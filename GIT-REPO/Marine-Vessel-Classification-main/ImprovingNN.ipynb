{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d361e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a954bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661fad08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2823080.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2870024.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2662125.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2900420.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2804883.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  category\n",
       "0  2823080.jpg         1\n",
       "1  2870024.jpg         1\n",
       "2  2662125.jpg         2\n",
       "3  2900420.jpg         3\n",
       "4  2804883.jpg         2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70b3bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/harita_addanki/opt/anaconda3/lib/python3.9/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/harita_addanki/opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e4b172f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae95949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['category']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997f93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data['image']\n",
    "labels = data['category'].replace({1:1,2:0,3:0,4:0,5:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7f5f01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "126f4efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the traindata into training and validation data\n",
    "train_X,valid_X,train_Y,valid_Y = train_test_split(data_x,labels,test_size=0.2,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "174d1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(data): \n",
    "    data = data\n",
    "    #x = np.array(data['image'])\n",
    "    #la = np.array(data['category'])\n",
    "    new = []\n",
    "    for i in data:\n",
    "        y = cv2.imread(i , 1)\n",
    "        res = cv2.resize(y , (15,8))\n",
    "        new.append(res)\n",
    "    new = np.array(new)\n",
    "    print(data.info())\n",
    "    print(data.describe())\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dcc035f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 5001 entries, 5808 to 3204\n",
      "Series name: image\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "5001 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 78.1+ KB\n",
      "None\n",
      "count            5001\n",
      "unique           5001\n",
      "top       2874633.jpg\n",
      "freq                1\n",
      "Name: image, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_x = pre_process(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fe505f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5001, 8, 15, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e6b7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unrolled_array = train_x.reshape(8*15*3,train_x.shape[0])\n",
    "Normed_array = Unrolled_array/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90c3ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5da1a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5001,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "796454b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = train_Y.values.reshape((1,train_Y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b5b10c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "595dad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout \n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c98206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f47396cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential([\n",
    "                    Flatten(input_shape = (8, 15,3)),\n",
    "                     Dense(2, activation = 'relu', input_shape = (360,)),\n",
    "                    Dense(4, activation = 'relu'),\n",
    "                    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e76a796c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 3751)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Normed_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bbbae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Training  - nothing changed here!\n",
    "\n",
    "nn_model.compile(\n",
    "    optimizer = 'adam',  \n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['binary_accuracy'] \n",
    ")\n",
    "history = nn_model.fit(train_x, train_y, epochs = 38 , batch_size = 256, verbose = 0,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "135f4742",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9da2dea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.589412</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.694810</td>\n",
       "      <td>0.359521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.694009</td>\n",
       "      <td>0.350333</td>\n",
       "      <td>0.693001</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.692245</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.691656</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.690536</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.690227</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.688802</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.688774</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.687049</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.687345</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.685282</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.685971</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.683642</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.684576</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.681939</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.683263</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.680333</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.681970</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.678721</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.680746</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.677214</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.679522</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.675697</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.678341</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.674225</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.677204</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.672774</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.676120</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.671412</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.675052</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.670060</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.674018</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.668742</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.673024</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.667505</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.672028</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.666210</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.671132</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.665063</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.670226</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.663881</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.669371</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.662795</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.668515</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.661651</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.667736</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.660590</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.666984</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.659565</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.666257</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.658601</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.665533</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.657603</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.664866</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.656698</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.664200</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.655792</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.663565</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.654905</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.662963</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.654063</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.662382</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.653247</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.661821</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.652435</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.661301</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.651679</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.660796</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.650949</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.660304</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.650243</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.659834</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.649527</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.659410</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  binary_accuracy  val_loss  val_binary_accuracy\n",
       "0   9.589412         0.448000  0.694810             0.359521\n",
       "1   0.694009         0.350333  0.693001             0.640479\n",
       "2   0.692245         0.670000  0.691656             0.640479\n",
       "3   0.690536         0.670000  0.690227             0.640479\n",
       "4   0.688802         0.670000  0.688774             0.640479\n",
       "5   0.687049         0.670000  0.687345             0.640479\n",
       "6   0.685282         0.670000  0.685971             0.640479\n",
       "7   0.683642         0.670000  0.684576             0.640479\n",
       "8   0.681939         0.670000  0.683263             0.640479\n",
       "9   0.680333         0.670000  0.681970             0.640479\n",
       "10  0.678721         0.670000  0.680746             0.640479\n",
       "11  0.677214         0.670000  0.679522             0.640479\n",
       "12  0.675697         0.670000  0.678341             0.640479\n",
       "13  0.674225         0.670000  0.677204             0.640479\n",
       "14  0.672774         0.670000  0.676120             0.640479\n",
       "15  0.671412         0.670000  0.675052             0.640479\n",
       "16  0.670060         0.670000  0.674018             0.640479\n",
       "17  0.668742         0.670000  0.673024             0.640479\n",
       "18  0.667505         0.670000  0.672028             0.640479\n",
       "19  0.666210         0.670000  0.671132             0.640479\n",
       "20  0.665063         0.670000  0.670226             0.640479\n",
       "21  0.663881         0.670000  0.669371             0.640479\n",
       "22  0.662795         0.670000  0.668515             0.640479\n",
       "23  0.661651         0.670000  0.667736             0.640479\n",
       "24  0.660590         0.670000  0.666984             0.640479\n",
       "25  0.659565         0.670000  0.666257             0.640479\n",
       "26  0.658601         0.670000  0.665533             0.640479\n",
       "27  0.657603         0.670000  0.664866             0.640479\n",
       "28  0.656698         0.670000  0.664200             0.640479\n",
       "29  0.655792         0.670000  0.663565             0.640479\n",
       "30  0.654905         0.670000  0.662963             0.640479\n",
       "31  0.654063         0.670000  0.662382             0.640479\n",
       "32  0.653247         0.670000  0.661821             0.640479\n",
       "33  0.652435         0.670000  0.661301             0.640479\n",
       "34  0.651679         0.670000  0.660796             0.640479\n",
       "35  0.650949         0.670000  0.660304             0.640479\n",
       "36  0.650243         0.670000  0.659834             0.640479\n",
       "37  0.649527         0.670000  0.659410             0.640479"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fe562c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fd0cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#l2 regularizer\n",
    "\n",
    "nn_model = Sequential([\n",
    "                    Flatten(input_shape = (8, 15,3)),\n",
    "                     Dense(2, activation = 'relu', input_shape = (360,),kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "                    Dense(4, activation = 'relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "                    Dense(1, activation = 'sigmoid',kernel_regularizer=tf.keras.regularizers.l2(0.001))\n",
    "])\n",
    "\n",
    "# the weight matrix is sometimes called the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "456aa343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Training  - nothing changed here!\n",
    "\n",
    "nn_model.compile(\n",
    "    optimizer = 'adam',  \n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['binary_accuracy'] \n",
    ")\n",
    "history = nn_model.fit(train_x, train_y, epochs = 38 , batch_size = 256, verbose = 0,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da24aa12",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.288795</td>\n",
       "      <td>0.630333</td>\n",
       "      <td>7.846634</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.939353</td>\n",
       "      <td>0.647667</td>\n",
       "      <td>4.816586</td>\n",
       "      <td>0.627164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.091829</td>\n",
       "      <td>0.640667</td>\n",
       "      <td>3.345617</td>\n",
       "      <td>0.625832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.924134</td>\n",
       "      <td>0.629333</td>\n",
       "      <td>2.643651</td>\n",
       "      <td>0.623169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.244649</td>\n",
       "      <td>0.621000</td>\n",
       "      <td>2.101789</td>\n",
       "      <td>0.620506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.800270</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>1.618652</td>\n",
       "      <td>0.632490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.451615</td>\n",
       "      <td>0.647333</td>\n",
       "      <td>1.318091</td>\n",
       "      <td>0.621838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.132222</td>\n",
       "      <td>0.637333</td>\n",
       "      <td>1.004168</td>\n",
       "      <td>0.600533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.828054</td>\n",
       "      <td>0.561667</td>\n",
       "      <td>0.836983</td>\n",
       "      <td>0.467377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.750297</td>\n",
       "      <td>0.461000</td>\n",
       "      <td>0.761110</td>\n",
       "      <td>0.476698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.732074</td>\n",
       "      <td>0.504667</td>\n",
       "      <td>0.751713</td>\n",
       "      <td>0.498003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.724449</td>\n",
       "      <td>0.480667</td>\n",
       "      <td>0.733838</td>\n",
       "      <td>0.455393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.719005</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.731284</td>\n",
       "      <td>0.450067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.715531</td>\n",
       "      <td>0.469667</td>\n",
       "      <td>0.734993</td>\n",
       "      <td>0.478029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.714006</td>\n",
       "      <td>0.484667</td>\n",
       "      <td>0.731024</td>\n",
       "      <td>0.460719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.711853</td>\n",
       "      <td>0.463333</td>\n",
       "      <td>0.727858</td>\n",
       "      <td>0.455393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.709984</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.726156</td>\n",
       "      <td>0.458056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.708044</td>\n",
       "      <td>0.464667</td>\n",
       "      <td>0.724244</td>\n",
       "      <td>0.459387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.706547</td>\n",
       "      <td>0.479333</td>\n",
       "      <td>0.725124</td>\n",
       "      <td>0.471372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.704535</td>\n",
       "      <td>0.471000</td>\n",
       "      <td>0.721498</td>\n",
       "      <td>0.459387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.702858</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.720803</td>\n",
       "      <td>0.466045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.702131</td>\n",
       "      <td>0.586333</td>\n",
       "      <td>0.721433</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.700645</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>0.714333</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.698902</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>0.714067</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.696468</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>0.714522</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.696005</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>0.710578</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.694993</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>0.716392</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.692972</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>0.707668</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.691084</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>0.706002</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.689079</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>0.705909</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.687826</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>0.708229</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.686108</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>0.703385</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.685594</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>0.700336</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.683066</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>0.702660</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.682462</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>0.701592</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.682262</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>0.695575</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.681814</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>0.694346</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.679271</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>0.698634</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  binary_accuracy  val_loss  val_binary_accuracy\n",
       "0   8.288795         0.630333  7.846634             0.640479\n",
       "1   5.939353         0.647667  4.816586             0.627164\n",
       "2   4.091829         0.640667  3.345617             0.625832\n",
       "3   2.924134         0.629333  2.643651             0.623169\n",
       "4   2.244649         0.621000  2.101789             0.620506\n",
       "5   1.800270         0.640000  1.618652             0.632490\n",
       "6   1.451615         0.647333  1.318091             0.621838\n",
       "7   1.132222         0.637333  1.004168             0.600533\n",
       "8   0.828054         0.561667  0.836983             0.467377\n",
       "9   0.750297         0.461000  0.761110             0.476698\n",
       "10  0.732074         0.504667  0.751713             0.498003\n",
       "11  0.724449         0.480667  0.733838             0.455393\n",
       "12  0.719005         0.436667  0.731284             0.450067\n",
       "13  0.715531         0.469667  0.734993             0.478029\n",
       "14  0.714006         0.484667  0.731024             0.460719\n",
       "15  0.711853         0.463333  0.727858             0.455393\n",
       "16  0.709984         0.463000  0.726156             0.458056\n",
       "17  0.708044         0.464667  0.724244             0.459387\n",
       "18  0.706547         0.479333  0.725124             0.471372\n",
       "19  0.704535         0.471000  0.721498             0.459387\n",
       "20  0.702858         0.470000  0.720803             0.466045\n",
       "21  0.702131         0.586333  0.721433             0.640479\n",
       "22  0.700645         0.671333  0.714333             0.640479\n",
       "23  0.698902         0.671333  0.714067             0.640479\n",
       "24  0.696468         0.671333  0.714522             0.640479\n",
       "25  0.696005         0.671333  0.710578             0.640479\n",
       "26  0.694993         0.671000  0.716392             0.640479\n",
       "27  0.692972         0.671333  0.707668             0.640479\n",
       "28  0.691084         0.671000  0.706002             0.640479\n",
       "29  0.689079         0.671333  0.705909             0.640479\n",
       "30  0.687826         0.671333  0.708229             0.640479\n",
       "31  0.686108         0.671333  0.703385             0.640479\n",
       "32  0.685594         0.671000  0.700336             0.640479\n",
       "33  0.683066         0.671333  0.702660             0.640479\n",
       "34  0.682462         0.671333  0.701592             0.640479\n",
       "35  0.682262         0.671333  0.695575             0.640479\n",
       "36  0.681814         0.671000  0.694346             0.640479\n",
       "37  0.679271         0.671333  0.698634             0.640479"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321e2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4dbf0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential([\n",
    "                    Flatten(input_shape = (8, 15,3)),\n",
    "                    Dense(2, activation = 'relu', input_shape = (360,)),\n",
    "                    Dropout(0.5),#dropout rate \n",
    "                    Dense(4, activation = 'relu'),\n",
    "                    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d536ed2d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.384525</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.691603</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.697886</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.690110</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.688650</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.688666</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.686906</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.687219</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.685151</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.685818</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.686676</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.684449</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.681775</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.683100</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.680111</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.681813</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.681671</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.680531</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.679992</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.679334</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.675420</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.678150</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.673949</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.676980</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.672494</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.675850</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.671063</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.674782</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.669738</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.673721</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.671286</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.672729</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.669897</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.671761</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.668580</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.670802</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.664636</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.669909</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.665938</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.669068</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.668222</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.663443</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.667409</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.660136</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.666658</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.659148</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.665897</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.658108</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.665202</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.657156</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.664510</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.658199</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.663854</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.657185</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.663237</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.654432</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.662610</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.653572</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.662025</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.654340</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.661505</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.651985</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.660961</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.652654</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.660459</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.650463</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.659986</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.649755</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.659533</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.650315</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.659088</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.649418</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.658693</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.648607</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.658285</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  binary_accuracy  val_loss  val_binary_accuracy\n",
       "0   1.384525         0.646000  0.691603             0.640479\n",
       "1   0.697886         0.669667  0.690110             0.640479\n",
       "2   0.688650         0.670000  0.688666             0.640479\n",
       "3   0.686906         0.670000  0.687219             0.640479\n",
       "4   0.685151         0.670000  0.685818             0.640479\n",
       "5   0.686676         0.669667  0.684449             0.640479\n",
       "6   0.681775         0.670000  0.683100             0.640479\n",
       "7   0.680111         0.670000  0.681813             0.640479\n",
       "8   0.681671         0.669667  0.680531             0.640479\n",
       "9   0.679992         0.669667  0.679334             0.640479\n",
       "10  0.675420         0.670000  0.678150             0.640479\n",
       "11  0.673949         0.670000  0.676980             0.640479\n",
       "12  0.672494         0.670000  0.675850             0.640479\n",
       "13  0.671063         0.670000  0.674782             0.640479\n",
       "14  0.669738         0.670000  0.673721             0.640479\n",
       "15  0.671286         0.669667  0.672729             0.640479\n",
       "16  0.669897         0.669667  0.671761             0.640479\n",
       "17  0.668580         0.669667  0.670802             0.640479\n",
       "18  0.664636         0.670000  0.669909             0.640479\n",
       "19  0.665938         0.669667  0.669068             0.640479\n",
       "20  0.664729         0.669667  0.668222             0.640479\n",
       "21  0.663443         0.669667  0.667409             0.640479\n",
       "22  0.660136         0.670000  0.666658             0.640479\n",
       "23  0.659148         0.670000  0.665897             0.640479\n",
       "24  0.658108         0.670000  0.665202             0.640479\n",
       "25  0.657156         0.670000  0.664510             0.640479\n",
       "26  0.658199         0.669667  0.663854             0.640479\n",
       "27  0.657185         0.669667  0.663237             0.640479\n",
       "28  0.654432         0.670000  0.662610             0.640479\n",
       "29  0.653572         0.670000  0.662025             0.640479\n",
       "30  0.654340         0.669667  0.661505             0.640479\n",
       "31  0.651985         0.670000  0.660961             0.640479\n",
       "32  0.652654         0.669667  0.660459             0.640479\n",
       "33  0.650463         0.670000  0.659986             0.640479\n",
       "34  0.649755         0.670000  0.659533             0.640479\n",
       "35  0.650315         0.669667  0.659088             0.640479\n",
       "36  0.649418         0.669667  0.658693             0.640479\n",
       "37  0.648607         0.669667  0.658285             0.640479"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Training  - nothing changed here!\n",
    "\n",
    "nn_model.compile(\n",
    "    optimizer = 'adam',  \n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['binary_accuracy'] \n",
    ")\n",
    "history = nn_model.fit(train_x, train_y, epochs = 38 , batch_size = 256, verbose = 0,validation_split=0.2)\n",
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2300ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4414bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential([\n",
    "                    Flatten(input_shape = (8, 15,3)),\n",
    "                    Dense(2, activation = 'relu', input_shape = (360,)),\n",
    "                    Dense(4, activation = 'relu'),\n",
    "                    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2587f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "823892f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n",
      "12/12 - 0s - loss: 1.6630 - binary_accuracy: 0.6557 - val_loss: 0.6916 - val_binary_accuracy: 0.6405 - 303ms/epoch - 25ms/step\n",
      "Epoch 2/38\n",
      "12/12 - 0s - loss: 0.6904 - binary_accuracy: 0.6700 - val_loss: 0.6901 - val_binary_accuracy: 0.6405 - 25ms/epoch - 2ms/step\n",
      "Epoch 3/38\n",
      "12/12 - 0s - loss: 0.6886 - binary_accuracy: 0.6700 - val_loss: 0.6885 - val_binary_accuracy: 0.6405 - 26ms/epoch - 2ms/step\n",
      "Epoch 4/38\n",
      "12/12 - 0s - loss: 0.6867 - binary_accuracy: 0.6700 - val_loss: 0.6871 - val_binary_accuracy: 0.6405 - 26ms/epoch - 2ms/step\n",
      "Epoch 5/38\n",
      "12/12 - 0s - loss: 0.6849 - binary_accuracy: 0.6700 - val_loss: 0.6856 - val_binary_accuracy: 0.6405 - 27ms/epoch - 2ms/step\n",
      "Epoch 6/38\n",
      "12/12 - 0s - loss: 0.6832 - binary_accuracy: 0.6700 - val_loss: 0.6842 - val_binary_accuracy: 0.6405 - 30ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.662959</td>\n",
       "      <td>0.655667</td>\n",
       "      <td>0.691581</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.690414</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.690065</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.688584</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.688548</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.687075</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.684930</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.685649</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.683207</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.684233</td>\n",
       "      <td>0.640479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  binary_accuracy  val_loss  val_binary_accuracy\n",
       "0  1.662959         0.655667  0.691581             0.640479\n",
       "1  0.690414         0.670000  0.690065             0.640479\n",
       "2  0.688584         0.670000  0.688548             0.640479\n",
       "3  0.686747         0.670000  0.687075             0.640479\n",
       "4  0.684930         0.670000  0.685649             0.640479\n",
       "5  0.683207         0.670000  0.684233             0.640479"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Training - nothing changed here!\n",
    "\n",
    "nn_model.compile(\n",
    "    optimizer = 'adam',  \n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['binary_accuracy'] \n",
    ")\n",
    "\n",
    "# fit the model with validation set  \n",
    "\n",
    "history = nn_model.fit(train_x, train_y, epochs = 38, batch_size = 256, verbose = 2, validation_split=0.2,\n",
    "                    callbacks=[early_stopping]) \n",
    "# The 0.2 means that 20 percent of the training data will be held back for validation.\n",
    "\n",
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8733f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3d91b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_utils import sigmoid, relu, compute_loss, forward_propagation, backward_propagation\n",
    "from init_utils import update_parameters, load_dataset,predict, plot_decision_boundary, predict_dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86891021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, learning_rate = 0.01, num_iterations = 10000, print_cost = True, initialization = \"he\"):\n",
    "    \"\"\"\n",
    "    Implements a three-layer neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (2, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 for red dots; 1 for blue dots), of shape (1, number of examples)\n",
    "    learning_rate -- learning rate for gradient descent \n",
    "    num_iterations -- number of iterations to run gradient descent\n",
    "    print_cost -- if True, print the cost every 1000 iterations\n",
    "    initialization -- flag to choose which initialization to use (\"zeros\",\"random\" or \"he\")\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model\n",
    "    \"\"\"\n",
    "        \n",
    "    grads = {}\n",
    "    costs = [] # to keep track of the loss\n",
    "    m = X.shape[1] # number of examples\n",
    "    layers_dims = [X.shape[0], 2, 4, 1]\n",
    "    \n",
    "    # Initialize parameters dictionary.\n",
    "    if initialization == \"zeros\":\n",
    "        parameters = initialize_parameters_zeros(layers_dims)\n",
    "    elif initialization == \"random\":\n",
    "        parameters = initialize_parameters_random(layers_dims)\n",
    "    elif initialization == \"he\":\n",
    "        parameters = initialize_parameters_he(layers_dims)\n",
    "\n",
    "    # Loop (gradient descent)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID.\n",
    "        a3, cache = forward_propagation(X, parameters)\n",
    "        \n",
    "        # Loss\n",
    "        cost = compute_loss(a3, Y)\n",
    "\n",
    "        # Backward propagation.\n",
    "        grads = backward_propagation(X, Y, cache)\n",
    "        \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        # Print the loss every 1000 iterations\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, cost))\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the loss\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f75141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_zeros(layers_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the size of each layer.\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
    "                    b1 -- bias vector of shape (layers_dims[1], 1)\n",
    "                    ...\n",
    "                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
    "                    bL -- bias vector of shape (layers_dims[L], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layers_dims)            # number of layers in the network\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.zeros((layers_dims[l],layers_dims[l-1]))\n",
    "        parameters['b' + str(l)] = np.zeros((layers_dims[l],1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e303eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_random(layers_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the size of each layer.\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
    "                    b1 -- bias vector of shape (layers_dims[1], 1)\n",
    "                    ...\n",
    "                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
    "                    bL -- bias vector of shape (layers_dims[L], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)               # This seed makes sure your \"random\" numbers will be the as ours\n",
    "    parameters = {}\n",
    "    L = len(layers_dims)            # integer representing the number of layers\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layers_dims[l],layers_dims[l-1]) * 10\n",
    "        parameters['b' + str(l)] = np.zeros((layers_dims[l], 1)) \n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b25745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_he(layers_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the size of each layer.\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
    "                    b1 -- bias vector of shape (layers_dims[1], 1)\n",
    "                    ...\n",
    "                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
    "                    bL -- bias vector of shape (layers_dims[L], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layers_dims) - 1 # integer representing the number of layers\n",
    "     \n",
    "    for l in range(1, L + 1):\n",
    "        parameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * np.sqrt(2/layers_dims[l-1])\n",
    "        parameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aad4b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_x\n",
    "train_Y = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8eaa8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = train_Y.reshape((1,train_Y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "023a93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(8*15*3,train_x.shape[0])\n",
    "train_X = train_X/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e48168d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6931471805599453\n",
      "Cost after iteration 1000: 0.6435423404418876\n",
      "Cost after iteration 2000: 0.6430955232438762\n",
      "Cost after iteration 3000: 0.6430907369288391\n",
      "Cost after iteration 4000: 0.6430906845707421\n",
      "Cost after iteration 5000: 0.6430906839967188\n",
      "Cost after iteration 6000: 0.6430906839904242\n",
      "Cost after iteration 7000: 0.6430906839903553\n",
      "Cost after iteration 8000: 0.6430906839903546\n",
      "Cost after iteration 9000: 0.6430906839903543\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the train set:\n",
      "Accuracy: 0.6568686262747451\n"
     ]
    }
   ],
   "source": [
    "parameters = model(train_X, train_Y, initialization = \"zeros\")\n",
    "print (\"On the train set:\")\n",
    "predictions_train = predict(train_X, train_Y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97fbe9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harita_addanki/Desktop/Classes/DEEP LEARNING/HW2/SHIP-CLASSIFICATION/train/init_utils.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  s = 1/(1+np.exp(-x))\n",
      "/Users/harita_addanki/Desktop/Classes/DEEP LEARNING/HW2/SHIP-CLASSIFICATION/train/init_utils.py:145: RuntimeWarning: divide by zero encountered in log\n",
      "  logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)\n",
      "/Users/harita_addanki/Desktop/Classes/DEEP LEARNING/HW2/SHIP-CLASSIFICATION/train/init_utils.py:145: RuntimeWarning: invalid value encountered in multiply\n",
      "  logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: inf\n",
      "Cost after iteration 1000: 0.8354639782019526\n",
      "Cost after iteration 2000: 0.7449343492325382\n",
      "Cost after iteration 3000: 0.6914857102334236\n",
      "Cost after iteration 4000: 0.6655357408912072\n",
      "Cost after iteration 5000: 0.6539054804775469\n",
      "Cost after iteration 6000: 0.6482666015124573\n",
      "Cost after iteration 7000: 0.6453456995151771\n",
      "Cost after iteration 8000: 0.643993047942117\n",
      "Cost after iteration 9000: 0.6433367557133564\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the train set:\n",
      "Accuracy: 0.6568686262747451\n"
     ]
    }
   ],
   "source": [
    "parameters = model(train_X, train_Y, initialization = \"random\")\n",
    "print (\"On the train set:\")\n",
    "predictions_train = predict(train_X, train_Y, parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b03728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.7260880114974172\n",
      "Cost after iteration 1000: 0.6430002429178876\n",
      "Cost after iteration 2000: 0.6417685822269072\n",
      "Cost after iteration 3000: 0.6406959961933726\n",
      "Cost after iteration 4000: 0.6394950845468004\n",
      "Cost after iteration 5000: 0.6378712019132821\n",
      "Cost after iteration 6000: 0.6360740258211117\n",
      "Cost after iteration 7000: 0.6340842225206563\n",
      "Cost after iteration 8000: 0.6317027192281357\n",
      "Cost after iteration 9000: 0.628323112673181\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the train set:\n",
      "Accuracy: 0.6568686262747451\n"
     ]
    }
   ],
   "source": [
    "parameters = model(train_X, train_Y, initialization = \"he\")\n",
    "print (\"On the train set:\")\n",
    "predictions_train = predict(train_X, train_Y, parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8db1abbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zeroes</th>\n",
       "      <th>random</th>\n",
       "      <th>he</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.40%</td>\n",
       "      <td>66.46%</td>\n",
       "      <td>66.40%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zeroes  random      he\n",
       "0  66.40%  66.46%  66.40%"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array([['66.40%', '66.46%', '66.40%']]),\n",
    "                   columns=['zeroes', 'random', 'he'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae790215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b62bb9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential([\n",
    "                    Flatten(input_shape = (8, 15,3)),\n",
    "                    BatchNormalization(),  # <- Batch normalization layer 1\n",
    "                    Dense(2, activation = 'relu', input_shape = (360,)),\n",
    "                    BatchNormalization(),  # <- Batch normalization layer 1\n",
    "                    Dense(4, activation = 'relu'),\n",
    "                    BatchNormalization(),  # <- Batch normalization layer 1\n",
    "                    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "def5fa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 - 1s - loss: 0.7465 - binary_accuracy: 0.4558 - val_loss: 2.2821 - val_binary_accuracy: 0.6838 - 572ms/epoch - 11ms/step\n",
      "Epoch 2/100\n",
      "50/50 - 0s - loss: 0.6800 - binary_accuracy: 0.5561 - val_loss: 1.0805 - val_binary_accuracy: 0.6856 - 67ms/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "50/50 - 0s - loss: 0.6548 - binary_accuracy: 0.6164 - val_loss: 0.7599 - val_binary_accuracy: 0.6856 - 60ms/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "50/50 - 0s - loss: 0.6409 - binary_accuracy: 0.6408 - val_loss: 0.6719 - val_binary_accuracy: 0.6838 - 58ms/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "50/50 - 0s - loss: 0.6332 - binary_accuracy: 0.6509 - val_loss: 0.6478 - val_binary_accuracy: 0.6838 - 67ms/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "50/50 - 0s - loss: 0.6276 - binary_accuracy: 0.6637 - val_loss: 0.6407 - val_binary_accuracy: 0.6838 - 67ms/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "50/50 - 0s - loss: 0.6226 - binary_accuracy: 0.6641 - val_loss: 0.6304 - val_binary_accuracy: 0.6838 - 63ms/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "50/50 - 0s - loss: 0.6196 - binary_accuracy: 0.6666 - val_loss: 0.6217 - val_binary_accuracy: 0.6838 - 64ms/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "50/50 - 0s - loss: 0.6161 - binary_accuracy: 0.6706 - val_loss: 0.6197 - val_binary_accuracy: 0.6856 - 67ms/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "50/50 - 0s - loss: 0.6147 - binary_accuracy: 0.6710 - val_loss: 0.6190 - val_binary_accuracy: 0.6785 - 65ms/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "50/50 - 0s - loss: 0.6103 - binary_accuracy: 0.6753 - val_loss: 0.6190 - val_binary_accuracy: 0.6679 - 65ms/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "50/50 - 0s - loss: 0.6100 - binary_accuracy: 0.6744 - val_loss: 0.6194 - val_binary_accuracy: 0.6767 - 65ms/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "50/50 - 0s - loss: 0.6048 - binary_accuracy: 0.6741 - val_loss: 0.6252 - val_binary_accuracy: 0.6679 - 63ms/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "50/50 - 0s - loss: 0.6062 - binary_accuracy: 0.6779 - val_loss: 0.6256 - val_binary_accuracy: 0.6643 - 62ms/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "50/50 - 0s - loss: 0.6040 - binary_accuracy: 0.6876 - val_loss: 0.6321 - val_binary_accuracy: 0.6714 - 64ms/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "50/50 - 0s - loss: 0.6044 - binary_accuracy: 0.6838 - val_loss: 0.6248 - val_binary_accuracy: 0.6767 - 64ms/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "50/50 - 0s - loss: 0.6018 - binary_accuracy: 0.6766 - val_loss: 0.6222 - val_binary_accuracy: 0.6803 - 63ms/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "50/50 - 0s - loss: 0.5995 - binary_accuracy: 0.6826 - val_loss: 0.6295 - val_binary_accuracy: 0.6625 - 62ms/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "50/50 - 0s - loss: 0.6026 - binary_accuracy: 0.6826 - val_loss: 0.6214 - val_binary_accuracy: 0.6696 - 64ms/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "50/50 - 0s - loss: 0.5948 - binary_accuracy: 0.6895 - val_loss: 0.6228 - val_binary_accuracy: 0.6590 - 65ms/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "50/50 - 0s - loss: 0.5920 - binary_accuracy: 0.6907 - val_loss: 0.6274 - val_binary_accuracy: 0.6625 - 64ms/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "50/50 - 0s - loss: 0.5991 - binary_accuracy: 0.6804 - val_loss: 0.6287 - val_binary_accuracy: 0.6661 - 64ms/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "50/50 - 0s - loss: 0.5911 - binary_accuracy: 0.6939 - val_loss: 0.6275 - val_binary_accuracy: 0.6590 - 65ms/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "50/50 - 0s - loss: 0.5928 - binary_accuracy: 0.6992 - val_loss: 0.6332 - val_binary_accuracy: 0.6554 - 76ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "50/50 - 0s - loss: 0.5909 - binary_accuracy: 0.7014 - val_loss: 0.6330 - val_binary_accuracy: 0.6465 - 63ms/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "50/50 - 0s - loss: 0.5884 - binary_accuracy: 0.6992 - val_loss: 0.6325 - val_binary_accuracy: 0.6430 - 75ms/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "50/50 - 0s - loss: 0.5879 - binary_accuracy: 0.7017 - val_loss: 0.6323 - val_binary_accuracy: 0.6590 - 71ms/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "50/50 - 0s - loss: 0.5851 - binary_accuracy: 0.7039 - val_loss: 0.6338 - val_binary_accuracy: 0.6536 - 65ms/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "50/50 - 0s - loss: 0.5827 - binary_accuracy: 0.7058 - val_loss: 0.6390 - val_binary_accuracy: 0.6536 - 70ms/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "50/50 - 0s - loss: 0.5821 - binary_accuracy: 0.7029 - val_loss: 0.6368 - val_binary_accuracy: 0.6448 - 72ms/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "50/50 - 0s - loss: 0.5819 - binary_accuracy: 0.7070 - val_loss: 0.6377 - val_binary_accuracy: 0.6643 - 71ms/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "50/50 - 0s - loss: 0.5799 - binary_accuracy: 0.7080 - val_loss: 0.6433 - val_binary_accuracy: 0.6359 - 69ms/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "50/50 - 0s - loss: 0.5768 - binary_accuracy: 0.7092 - val_loss: 0.6463 - val_binary_accuracy: 0.6412 - 69ms/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "50/50 - 0s - loss: 0.5780 - binary_accuracy: 0.7142 - val_loss: 0.6501 - val_binary_accuracy: 0.6554 - 69ms/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "50/50 - 0s - loss: 0.5781 - binary_accuracy: 0.7080 - val_loss: 0.6556 - val_binary_accuracy: 0.6412 - 70ms/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "50/50 - 0s - loss: 0.5765 - binary_accuracy: 0.7171 - val_loss: 0.6510 - val_binary_accuracy: 0.6519 - 79ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "50/50 - 0s - loss: 0.5720 - binary_accuracy: 0.7180 - val_loss: 0.6594 - val_binary_accuracy: 0.6323 - 66ms/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "50/50 - 0s - loss: 0.5754 - binary_accuracy: 0.7095 - val_loss: 0.6452 - val_binary_accuracy: 0.6590 - 64ms/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "50/50 - 0s - loss: 0.5710 - binary_accuracy: 0.7196 - val_loss: 0.6516 - val_binary_accuracy: 0.6696 - 63ms/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "50/50 - 0s - loss: 0.5743 - binary_accuracy: 0.7174 - val_loss: 0.6549 - val_binary_accuracy: 0.6572 - 74ms/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "50/50 - 0s - loss: 0.5705 - binary_accuracy: 0.7224 - val_loss: 0.6575 - val_binary_accuracy: 0.6465 - 67ms/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "50/50 - 0s - loss: 0.5684 - binary_accuracy: 0.7193 - val_loss: 0.6653 - val_binary_accuracy: 0.6519 - 60ms/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "50/50 - 0s - loss: 0.5699 - binary_accuracy: 0.7227 - val_loss: 0.6540 - val_binary_accuracy: 0.6572 - 62ms/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "50/50 - 0s - loss: 0.5681 - binary_accuracy: 0.7224 - val_loss: 0.6533 - val_binary_accuracy: 0.6412 - 62ms/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "50/50 - 0s - loss: 0.5685 - binary_accuracy: 0.7202 - val_loss: 0.6573 - val_binary_accuracy: 0.6412 - 64ms/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "50/50 - 0s - loss: 0.5657 - binary_accuracy: 0.7211 - val_loss: 0.6623 - val_binary_accuracy: 0.6430 - 64ms/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "50/50 - 0s - loss: 0.5598 - binary_accuracy: 0.7312 - val_loss: 0.6569 - val_binary_accuracy: 0.6572 - 64ms/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "50/50 - 0s - loss: 0.5640 - binary_accuracy: 0.7230 - val_loss: 0.6693 - val_binary_accuracy: 0.6359 - 73ms/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "50/50 - 0s - loss: 0.5624 - binary_accuracy: 0.7296 - val_loss: 0.6671 - val_binary_accuracy: 0.6536 - 65ms/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "50/50 - 0s - loss: 0.5634 - binary_accuracy: 0.7287 - val_loss: 0.6707 - val_binary_accuracy: 0.6394 - 72ms/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "50/50 - 0s - loss: 0.5570 - binary_accuracy: 0.7302 - val_loss: 0.6642 - val_binary_accuracy: 0.6519 - 67ms/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "50/50 - 0s - loss: 0.5632 - binary_accuracy: 0.7324 - val_loss: 0.6599 - val_binary_accuracy: 0.6625 - 61ms/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "50/50 - 0s - loss: 0.5607 - binary_accuracy: 0.7277 - val_loss: 0.6574 - val_binary_accuracy: 0.6412 - 62ms/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "50/50 - 0s - loss: 0.5590 - binary_accuracy: 0.7312 - val_loss: 0.6610 - val_binary_accuracy: 0.6554 - 61ms/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "50/50 - 0s - loss: 0.5604 - binary_accuracy: 0.7324 - val_loss: 0.6696 - val_binary_accuracy: 0.6359 - 63ms/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "50/50 - 0s - loss: 0.5577 - binary_accuracy: 0.7365 - val_loss: 0.6968 - val_binary_accuracy: 0.6412 - 64ms/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "50/50 - 0s - loss: 0.5573 - binary_accuracy: 0.7331 - val_loss: 0.6727 - val_binary_accuracy: 0.6448 - 64ms/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "50/50 - 0s - loss: 0.5542 - binary_accuracy: 0.7381 - val_loss: 0.6770 - val_binary_accuracy: 0.6448 - 64ms/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "50/50 - 0s - loss: 0.5558 - binary_accuracy: 0.7371 - val_loss: 0.6828 - val_binary_accuracy: 0.6412 - 64ms/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "50/50 - 0s - loss: 0.5514 - binary_accuracy: 0.7346 - val_loss: 0.6765 - val_binary_accuracy: 0.6412 - 66ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "50/50 - 0s - loss: 0.5574 - binary_accuracy: 0.7384 - val_loss: 0.6712 - val_binary_accuracy: 0.6377 - 65ms/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "50/50 - 0s - loss: 0.5536 - binary_accuracy: 0.7390 - val_loss: 0.6723 - val_binary_accuracy: 0.6323 - 61ms/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "50/50 - 0s - loss: 0.5509 - binary_accuracy: 0.7393 - val_loss: 0.6748 - val_binary_accuracy: 0.6448 - 60ms/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "50/50 - 0s - loss: 0.5539 - binary_accuracy: 0.7343 - val_loss: 0.6713 - val_binary_accuracy: 0.6448 - 60ms/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "50/50 - 0s - loss: 0.5481 - binary_accuracy: 0.7406 - val_loss: 0.6708 - val_binary_accuracy: 0.6483 - 61ms/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "50/50 - 0s - loss: 0.5504 - binary_accuracy: 0.7400 - val_loss: 0.6814 - val_binary_accuracy: 0.6519 - 62ms/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "50/50 - 0s - loss: 0.5445 - binary_accuracy: 0.7415 - val_loss: 0.6814 - val_binary_accuracy: 0.6465 - 60ms/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "50/50 - 0s - loss: 0.5509 - binary_accuracy: 0.7406 - val_loss: 0.6845 - val_binary_accuracy: 0.6430 - 59ms/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "50/50 - 0s - loss: 0.5452 - binary_accuracy: 0.7472 - val_loss: 0.6856 - val_binary_accuracy: 0.6306 - 59ms/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "50/50 - 0s - loss: 0.5465 - binary_accuracy: 0.7409 - val_loss: 0.6795 - val_binary_accuracy: 0.6341 - 60ms/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "50/50 - 0s - loss: 0.5493 - binary_accuracy: 0.7406 - val_loss: 0.7046 - val_binary_accuracy: 0.6341 - 61ms/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "50/50 - 0s - loss: 0.5474 - binary_accuracy: 0.7415 - val_loss: 0.6861 - val_binary_accuracy: 0.6323 - 58ms/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "50/50 - 0s - loss: 0.5421 - binary_accuracy: 0.7453 - val_loss: 0.6725 - val_binary_accuracy: 0.6448 - 61ms/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "50/50 - 0s - loss: 0.5491 - binary_accuracy: 0.7406 - val_loss: 0.6760 - val_binary_accuracy: 0.6412 - 64ms/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "50/50 - 0s - loss: 0.5486 - binary_accuracy: 0.7403 - val_loss: 0.6902 - val_binary_accuracy: 0.6359 - 66ms/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "50/50 - 0s - loss: 0.5449 - binary_accuracy: 0.7425 - val_loss: 0.7116 - val_binary_accuracy: 0.6234 - 68ms/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "50/50 - 0s - loss: 0.5405 - binary_accuracy: 0.7456 - val_loss: 0.6890 - val_binary_accuracy: 0.6412 - 64ms/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "50/50 - 0s - loss: 0.5423 - binary_accuracy: 0.7525 - val_loss: 0.6953 - val_binary_accuracy: 0.6306 - 69ms/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "50/50 - 0s - loss: 0.5463 - binary_accuracy: 0.7346 - val_loss: 0.6942 - val_binary_accuracy: 0.6430 - 67ms/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "50/50 - 0s - loss: 0.5392 - binary_accuracy: 0.7513 - val_loss: 0.6943 - val_binary_accuracy: 0.6306 - 67ms/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "50/50 - 0s - loss: 0.5452 - binary_accuracy: 0.7472 - val_loss: 0.6871 - val_binary_accuracy: 0.6412 - 64ms/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "50/50 - 0s - loss: 0.5366 - binary_accuracy: 0.7469 - val_loss: 0.6806 - val_binary_accuracy: 0.6554 - 61ms/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "50/50 - 0s - loss: 0.5382 - binary_accuracy: 0.7538 - val_loss: 0.6819 - val_binary_accuracy: 0.6394 - 71ms/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "50/50 - 0s - loss: 0.5429 - binary_accuracy: 0.7425 - val_loss: 0.6917 - val_binary_accuracy: 0.6394 - 59ms/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "50/50 - 0s - loss: 0.5383 - binary_accuracy: 0.7453 - val_loss: 0.6793 - val_binary_accuracy: 0.6359 - 64ms/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "50/50 - 0s - loss: 0.5354 - binary_accuracy: 0.7478 - val_loss: 0.6896 - val_binary_accuracy: 0.6430 - 78ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "50/50 - 0s - loss: 0.5344 - binary_accuracy: 0.7544 - val_loss: 0.6976 - val_binary_accuracy: 0.6448 - 76ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "50/50 - 0s - loss: 0.5366 - binary_accuracy: 0.7560 - val_loss: 0.6927 - val_binary_accuracy: 0.6234 - 71ms/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "50/50 - 0s - loss: 0.5343 - binary_accuracy: 0.7516 - val_loss: 0.6849 - val_binary_accuracy: 0.6412 - 64ms/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "50/50 - 0s - loss: 0.5316 - binary_accuracy: 0.7538 - val_loss: 0.6912 - val_binary_accuracy: 0.6430 - 64ms/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "50/50 - 0s - loss: 0.5364 - binary_accuracy: 0.7556 - val_loss: 0.7054 - val_binary_accuracy: 0.6217 - 61ms/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "50/50 - 0s - loss: 0.5334 - binary_accuracy: 0.7544 - val_loss: 0.6974 - val_binary_accuracy: 0.6323 - 63ms/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "50/50 - 0s - loss: 0.5353 - binary_accuracy: 0.7535 - val_loss: 0.6927 - val_binary_accuracy: 0.6323 - 62ms/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "50/50 - 0s - loss: 0.5322 - binary_accuracy: 0.7563 - val_loss: 0.6877 - val_binary_accuracy: 0.6448 - 62ms/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "50/50 - 0s - loss: 0.5331 - binary_accuracy: 0.7560 - val_loss: 0.7025 - val_binary_accuracy: 0.6377 - 63ms/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "50/50 - 0s - loss: 0.5327 - binary_accuracy: 0.7535 - val_loss: 0.6969 - val_binary_accuracy: 0.6394 - 60ms/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "50/50 - 0s - loss: 0.5316 - binary_accuracy: 0.7541 - val_loss: 0.7032 - val_binary_accuracy: 0.6341 - 62ms/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "50/50 - 0s - loss: 0.5351 - binary_accuracy: 0.7506 - val_loss: 0.7079 - val_binary_accuracy: 0.6288 - 61ms/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "50/50 - 0s - loss: 0.5401 - binary_accuracy: 0.7472 - val_loss: 0.6867 - val_binary_accuracy: 0.6519 - 62ms/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "50/50 - 0s - loss: 0.5375 - binary_accuracy: 0.7462 - val_loss: 0.7216 - val_binary_accuracy: 0.6110 - 62ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "\n",
    "nn_model.compile(optimizer = 'adam',  \n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['binary_accuracy'] )\n",
    "history = nn_model.fit(train_x,train_y , epochs=100, validation_split=0.15, batch_size=64,verbose=2)\n",
    "d1 = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7f84c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_metrics = history.history['binary_accuracy']\n",
    "val_metrics = history.history['val_binary_accuracy']\n",
    "epochs = range(1, len(train_metrics) + 1)\n",
    "plt.plot(epochs, train_metrics)\n",
    "plt.plot(epochs, val_metrics)\n",
    "plt.title('Training and validation '+ 'binary_accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel('binary_accuracy')\n",
    "plt.legend([\"train_\"+'binary_accuracy', 'val_'+'binary_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a929e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential([\n",
    "                    Flatten(input_shape = (8, 15,3)),\n",
    "                    BatchNormalization(\n",
    "        momentum=0.95, \n",
    "        epsilon=0.005,\n",
    "        beta_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05), \n",
    "        gamma_initializer=tf.keras.initializers.Constant(value=0.9)\n",
    "    ),\n",
    "                    Dense(2, activation = 'relu', input_shape = (360,)),\n",
    "BatchNormalization(\n",
    "        momentum=0.95, \n",
    "        epsilon=0.005,\n",
    "        beta_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05), \n",
    "        gamma_initializer=tf.keras.initializers.Constant(value=0.9)\n",
    "    ),                    Dense(4, activation = 'relu'),\n",
    "BatchNormalization(\n",
    "        momentum=0.95, \n",
    "        epsilon=0.005,\n",
    "        beta_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05), \n",
    "        gamma_initializer=tf.keras.initializers.Constant(value=0.9)\n",
    "    ),                    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "549a20c9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 - 1s - loss: 0.7215 - binary_accuracy: 0.5922 - val_loss: 0.6961 - val_binary_accuracy: 0.4263 - 617ms/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "50/50 - 0s - loss: 0.6791 - binary_accuracy: 0.6217 - val_loss: 0.6680 - val_binary_accuracy: 0.6483 - 74ms/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "50/50 - 0s - loss: 0.6604 - binary_accuracy: 0.6471 - val_loss: 0.6559 - val_binary_accuracy: 0.6519 - 63ms/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "50/50 - 0s - loss: 0.6512 - binary_accuracy: 0.6434 - val_loss: 0.6497 - val_binary_accuracy: 0.6661 - 68ms/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "50/50 - 0s - loss: 0.6470 - binary_accuracy: 0.6393 - val_loss: 0.6391 - val_binary_accuracy: 0.6696 - 70ms/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "50/50 - 0s - loss: 0.6389 - binary_accuracy: 0.6459 - val_loss: 0.6473 - val_binary_accuracy: 0.6696 - 68ms/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "50/50 - 0s - loss: 0.6371 - binary_accuracy: 0.6521 - val_loss: 0.6335 - val_binary_accuracy: 0.6750 - 69ms/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "50/50 - 0s - loss: 0.6310 - binary_accuracy: 0.6559 - val_loss: 0.6314 - val_binary_accuracy: 0.6838 - 68ms/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "50/50 - 0s - loss: 0.6284 - binary_accuracy: 0.6625 - val_loss: 0.6243 - val_binary_accuracy: 0.6838 - 68ms/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "50/50 - 0s - loss: 0.6273 - binary_accuracy: 0.6637 - val_loss: 0.6253 - val_binary_accuracy: 0.6838 - 68ms/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "50/50 - 0s - loss: 0.6248 - binary_accuracy: 0.6606 - val_loss: 0.6202 - val_binary_accuracy: 0.6838 - 63ms/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "50/50 - 0s - loss: 0.6234 - binary_accuracy: 0.6644 - val_loss: 0.6200 - val_binary_accuracy: 0.6838 - 63ms/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "50/50 - 0s - loss: 0.6204 - binary_accuracy: 0.6619 - val_loss: 0.6210 - val_binary_accuracy: 0.6838 - 62ms/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "50/50 - 0s - loss: 0.6213 - binary_accuracy: 0.6606 - val_loss: 0.6198 - val_binary_accuracy: 0.6838 - 69ms/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "50/50 - 0s - loss: 0.6187 - binary_accuracy: 0.6606 - val_loss: 0.6210 - val_binary_accuracy: 0.6838 - 82ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "50/50 - 0s - loss: 0.6175 - binary_accuracy: 0.6609 - val_loss: 0.6202 - val_binary_accuracy: 0.6838 - 94ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "50/50 - 0s - loss: 0.6197 - binary_accuracy: 0.6659 - val_loss: 0.6183 - val_binary_accuracy: 0.6838 - 72ms/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "50/50 - 0s - loss: 0.6173 - binary_accuracy: 0.6666 - val_loss: 0.6185 - val_binary_accuracy: 0.6838 - 67ms/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "50/50 - 0s - loss: 0.6155 - binary_accuracy: 0.6681 - val_loss: 0.6215 - val_binary_accuracy: 0.6838 - 64ms/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "50/50 - 0s - loss: 0.6137 - binary_accuracy: 0.6662 - val_loss: 0.6161 - val_binary_accuracy: 0.6838 - 70ms/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "50/50 - 0s - loss: 0.6147 - binary_accuracy: 0.6684 - val_loss: 0.6182 - val_binary_accuracy: 0.6838 - 68ms/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "50/50 - 0s - loss: 0.6141 - binary_accuracy: 0.6662 - val_loss: 0.6153 - val_binary_accuracy: 0.6838 - 68ms/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "50/50 - 0s - loss: 0.6132 - binary_accuracy: 0.6568 - val_loss: 0.6182 - val_binary_accuracy: 0.6838 - 69ms/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "50/50 - 0s - loss: 0.6117 - binary_accuracy: 0.6653 - val_loss: 0.6187 - val_binary_accuracy: 0.6838 - 65ms/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "50/50 - 0s - loss: 0.6100 - binary_accuracy: 0.6615 - val_loss: 0.6149 - val_binary_accuracy: 0.6838 - 66ms/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "50/50 - 0s - loss: 0.6095 - binary_accuracy: 0.6647 - val_loss: 0.6128 - val_binary_accuracy: 0.6838 - 67ms/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "50/50 - 0s - loss: 0.6080 - binary_accuracy: 0.6634 - val_loss: 0.6192 - val_binary_accuracy: 0.6838 - 68ms/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "50/50 - 0s - loss: 0.6076 - binary_accuracy: 0.6659 - val_loss: 0.6180 - val_binary_accuracy: 0.6838 - 67ms/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "50/50 - 0s - loss: 0.6071 - binary_accuracy: 0.6706 - val_loss: 0.6171 - val_binary_accuracy: 0.6838 - 68ms/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "50/50 - 0s - loss: 0.6060 - binary_accuracy: 0.6691 - val_loss: 0.6212 - val_binary_accuracy: 0.6838 - 68ms/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "50/50 - 0s - loss: 0.6030 - binary_accuracy: 0.6722 - val_loss: 0.6213 - val_binary_accuracy: 0.6625 - 70ms/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "50/50 - 0s - loss: 0.6066 - binary_accuracy: 0.6691 - val_loss: 0.6206 - val_binary_accuracy: 0.6696 - 77ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "50/50 - 0s - loss: 0.6042 - binary_accuracy: 0.6735 - val_loss: 0.6200 - val_binary_accuracy: 0.6643 - 73ms/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "50/50 - 0s - loss: 0.6070 - binary_accuracy: 0.6782 - val_loss: 0.6186 - val_binary_accuracy: 0.6732 - 68ms/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "50/50 - 0s - loss: 0.6024 - binary_accuracy: 0.6766 - val_loss: 0.6281 - val_binary_accuracy: 0.6590 - 72ms/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "50/50 - 0s - loss: 0.6004 - binary_accuracy: 0.6835 - val_loss: 0.6286 - val_binary_accuracy: 0.6714 - 78ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "50/50 - 0s - loss: 0.6011 - binary_accuracy: 0.6816 - val_loss: 0.6240 - val_binary_accuracy: 0.6625 - 69ms/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "50/50 - 0s - loss: 0.5998 - binary_accuracy: 0.6819 - val_loss: 0.6303 - val_binary_accuracy: 0.6661 - 74ms/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "50/50 - 0s - loss: 0.5988 - binary_accuracy: 0.6832 - val_loss: 0.6251 - val_binary_accuracy: 0.6661 - 61ms/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "50/50 - 0s - loss: 0.5983 - binary_accuracy: 0.6757 - val_loss: 0.6344 - val_binary_accuracy: 0.6679 - 58ms/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "50/50 - 0s - loss: 0.5965 - binary_accuracy: 0.6857 - val_loss: 0.6350 - val_binary_accuracy: 0.6661 - 59ms/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "50/50 - 0s - loss: 0.5976 - binary_accuracy: 0.6838 - val_loss: 0.6385 - val_binary_accuracy: 0.6661 - 60ms/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "50/50 - 0s - loss: 0.5947 - binary_accuracy: 0.6813 - val_loss: 0.6462 - val_binary_accuracy: 0.6572 - 74ms/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "50/50 - 0s - loss: 0.5974 - binary_accuracy: 0.6819 - val_loss: 0.6462 - val_binary_accuracy: 0.6501 - 80ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "50/50 - 0s - loss: 0.5978 - binary_accuracy: 0.6747 - val_loss: 0.6373 - val_binary_accuracy: 0.6519 - 72ms/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "50/50 - 0s - loss: 0.5949 - binary_accuracy: 0.6838 - val_loss: 0.6375 - val_binary_accuracy: 0.6501 - 61ms/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "50/50 - 0s - loss: 0.5929 - binary_accuracy: 0.6882 - val_loss: 0.6486 - val_binary_accuracy: 0.6430 - 58ms/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "50/50 - 0s - loss: 0.5959 - binary_accuracy: 0.6788 - val_loss: 0.6470 - val_binary_accuracy: 0.6341 - 62ms/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "50/50 - 0s - loss: 0.5901 - binary_accuracy: 0.6882 - val_loss: 0.6513 - val_binary_accuracy: 0.6306 - 61ms/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "50/50 - 0s - loss: 0.5914 - binary_accuracy: 0.6888 - val_loss: 0.6457 - val_binary_accuracy: 0.6341 - 76ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "50/50 - 0s - loss: 0.5928 - binary_accuracy: 0.6826 - val_loss: 0.6425 - val_binary_accuracy: 0.6519 - 81ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "50/50 - 0s - loss: 0.5943 - binary_accuracy: 0.6891 - val_loss: 0.6418 - val_binary_accuracy: 0.6554 - 77ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "50/50 - 0s - loss: 0.5941 - binary_accuracy: 0.6876 - val_loss: 0.6395 - val_binary_accuracy: 0.6661 - 70ms/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "50/50 - 0s - loss: 0.5897 - binary_accuracy: 0.6882 - val_loss: 0.6378 - val_binary_accuracy: 0.6643 - 69ms/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "50/50 - 0s - loss: 0.5903 - binary_accuracy: 0.6870 - val_loss: 0.6489 - val_binary_accuracy: 0.6643 - 81ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "50/50 - 0s - loss: 0.5893 - binary_accuracy: 0.6954 - val_loss: 0.6445 - val_binary_accuracy: 0.6732 - 81ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "50/50 - 0s - loss: 0.5907 - binary_accuracy: 0.6904 - val_loss: 0.6590 - val_binary_accuracy: 0.6536 - 80ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "50/50 - 0s - loss: 0.5852 - binary_accuracy: 0.6926 - val_loss: 0.6534 - val_binary_accuracy: 0.6501 - 62ms/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "50/50 - 0s - loss: 0.5846 - binary_accuracy: 0.6967 - val_loss: 0.6510 - val_binary_accuracy: 0.6590 - 60ms/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "50/50 - 0s - loss: 0.5804 - binary_accuracy: 0.7008 - val_loss: 0.6533 - val_binary_accuracy: 0.6625 - 62ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "50/50 - 0s - loss: 0.5818 - binary_accuracy: 0.6967 - val_loss: 0.6542 - val_binary_accuracy: 0.6590 - 63ms/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "50/50 - 0s - loss: 0.5816 - binary_accuracy: 0.6982 - val_loss: 0.6465 - val_binary_accuracy: 0.6643 - 62ms/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "50/50 - 0s - loss: 0.5832 - binary_accuracy: 0.7004 - val_loss: 0.6487 - val_binary_accuracy: 0.6572 - 60ms/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "50/50 - 0s - loss: 0.5818 - binary_accuracy: 0.6976 - val_loss: 0.6583 - val_binary_accuracy: 0.6625 - 65ms/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "50/50 - 0s - loss: 0.5772 - binary_accuracy: 0.7051 - val_loss: 0.6532 - val_binary_accuracy: 0.6448 - 64ms/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "50/50 - 0s - loss: 0.5829 - binary_accuracy: 0.6986 - val_loss: 0.6557 - val_binary_accuracy: 0.6572 - 61ms/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "50/50 - 0s - loss: 0.5759 - binary_accuracy: 0.7077 - val_loss: 0.6536 - val_binary_accuracy: 0.6679 - 59ms/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "50/50 - 0s - loss: 0.5806 - binary_accuracy: 0.7048 - val_loss: 0.6635 - val_binary_accuracy: 0.6625 - 59ms/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "50/50 - 0s - loss: 0.5776 - binary_accuracy: 0.7048 - val_loss: 0.6523 - val_binary_accuracy: 0.6607 - 57ms/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "50/50 - 0s - loss: 0.5726 - binary_accuracy: 0.7114 - val_loss: 0.6571 - val_binary_accuracy: 0.6643 - 58ms/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "50/50 - 0s - loss: 0.5742 - binary_accuracy: 0.7067 - val_loss: 0.6623 - val_binary_accuracy: 0.6554 - 64ms/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "50/50 - 0s - loss: 0.5769 - binary_accuracy: 0.7004 - val_loss: 0.6708 - val_binary_accuracy: 0.6465 - 74ms/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "50/50 - 0s - loss: 0.5721 - binary_accuracy: 0.7111 - val_loss: 0.6632 - val_binary_accuracy: 0.6607 - 78ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "50/50 - 0s - loss: 0.5689 - binary_accuracy: 0.7171 - val_loss: 0.6597 - val_binary_accuracy: 0.6679 - 69ms/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "50/50 - 0s - loss: 0.5670 - binary_accuracy: 0.7199 - val_loss: 0.6528 - val_binary_accuracy: 0.6696 - 64ms/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "50/50 - 0s - loss: 0.5737 - binary_accuracy: 0.7008 - val_loss: 0.6626 - val_binary_accuracy: 0.6377 - 69ms/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "50/50 - 0s - loss: 0.5692 - binary_accuracy: 0.7073 - val_loss: 0.6725 - val_binary_accuracy: 0.6448 - 66ms/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "50/50 - 0s - loss: 0.5696 - binary_accuracy: 0.7080 - val_loss: 0.6626 - val_binary_accuracy: 0.6643 - 62ms/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "50/50 - 0s - loss: 0.5724 - binary_accuracy: 0.7102 - val_loss: 0.6764 - val_binary_accuracy: 0.6394 - 60ms/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "50/50 - 0s - loss: 0.5688 - binary_accuracy: 0.7177 - val_loss: 0.6731 - val_binary_accuracy: 0.6483 - 61ms/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "50/50 - 0s - loss: 0.5680 - binary_accuracy: 0.7127 - val_loss: 0.6912 - val_binary_accuracy: 0.6377 - 59ms/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "50/50 - 0s - loss: 0.5664 - binary_accuracy: 0.7158 - val_loss: 0.6783 - val_binary_accuracy: 0.6643 - 61ms/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "50/50 - 0s - loss: 0.5627 - binary_accuracy: 0.7127 - val_loss: 0.6878 - val_binary_accuracy: 0.6341 - 59ms/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "50/50 - 0s - loss: 0.5673 - binary_accuracy: 0.7171 - val_loss: 0.6795 - val_binary_accuracy: 0.6412 - 58ms/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "50/50 - 0s - loss: 0.5632 - binary_accuracy: 0.7189 - val_loss: 0.6623 - val_binary_accuracy: 0.6554 - 59ms/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "50/50 - 0s - loss: 0.5641 - binary_accuracy: 0.7205 - val_loss: 0.6779 - val_binary_accuracy: 0.6448 - 61ms/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "50/50 - 0s - loss: 0.5622 - binary_accuracy: 0.7174 - val_loss: 0.6881 - val_binary_accuracy: 0.6536 - 58ms/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "50/50 - 0s - loss: 0.5581 - binary_accuracy: 0.7205 - val_loss: 0.6789 - val_binary_accuracy: 0.6465 - 60ms/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "50/50 - 0s - loss: 0.5620 - binary_accuracy: 0.7193 - val_loss: 0.6872 - val_binary_accuracy: 0.6554 - 59ms/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "50/50 - 0s - loss: 0.5635 - binary_accuracy: 0.7243 - val_loss: 0.6745 - val_binary_accuracy: 0.6501 - 59ms/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "50/50 - 0s - loss: 0.5619 - binary_accuracy: 0.7146 - val_loss: 0.6950 - val_binary_accuracy: 0.6448 - 59ms/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "50/50 - 0s - loss: 0.5625 - binary_accuracy: 0.7158 - val_loss: 0.6857 - val_binary_accuracy: 0.6536 - 58ms/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "50/50 - 0s - loss: 0.5606 - binary_accuracy: 0.7221 - val_loss: 0.6797 - val_binary_accuracy: 0.6483 - 65ms/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "50/50 - 0s - loss: 0.5565 - binary_accuracy: 0.7237 - val_loss: 0.6882 - val_binary_accuracy: 0.6448 - 67ms/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "50/50 - 0s - loss: 0.5600 - binary_accuracy: 0.7240 - val_loss: 0.6851 - val_binary_accuracy: 0.6607 - 73ms/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "50/50 - 0s - loss: 0.5649 - binary_accuracy: 0.7155 - val_loss: 0.6876 - val_binary_accuracy: 0.6465 - 65ms/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "50/50 - 0s - loss: 0.5565 - binary_accuracy: 0.7271 - val_loss: 0.6678 - val_binary_accuracy: 0.6536 - 61ms/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "50/50 - 0s - loss: 0.5544 - binary_accuracy: 0.7230 - val_loss: 0.6915 - val_binary_accuracy: 0.6536 - 60ms/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "50/50 - 0s - loss: 0.5539 - binary_accuracy: 0.7224 - val_loss: 0.6846 - val_binary_accuracy: 0.6465 - 63ms/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "50/50 - 0s - loss: 0.5568 - binary_accuracy: 0.7205 - val_loss: 0.6914 - val_binary_accuracy: 0.6519 - 70ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "\n",
    "nn_model.compile(optimizer = 'adam',  \n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['binary_accuracy'] )\n",
    "history = nn_model.fit(train_x,train_y , epochs=100, validation_split=0.15, batch_size=64,verbose=2)\n",
    "d2 = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54f2159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential([\n",
    "                    Flatten(input_shape = (8, 15,3)),\n",
    "                    BatchNormalization(),\n",
    "                    Dense(2, activation = 'relu', input_shape = (360,)),\n",
    "                    BatchNormalization(),                    \n",
    "                Dense(4, activation = 'relu'),\n",
    "BatchNormalization(\n",
    "        momentum=0.55, \n",
    "        epsilon=0.005,\n",
    "        beta_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05), \n",
    "        gamma_initializer=tf.keras.initializers.Constant(value=0.9)\n",
    "    ),                    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "599e1523",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 - 1s - loss: 0.7115 - binary_accuracy: 0.5602 - val_loss: 1.0219 - val_binary_accuracy: 0.6838 - 581ms/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "50/50 - 0s - loss: 0.6649 - binary_accuracy: 0.6101 - val_loss: 0.6814 - val_binary_accuracy: 0.6838 - 72ms/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "50/50 - 0s - loss: 0.6481 - binary_accuracy: 0.6311 - val_loss: 0.6528 - val_binary_accuracy: 0.6838 - 64ms/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "50/50 - 0s - loss: 0.6389 - binary_accuracy: 0.6584 - val_loss: 0.6282 - val_binary_accuracy: 0.6838 - 66ms/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "50/50 - 0s - loss: 0.6318 - binary_accuracy: 0.6650 - val_loss: 0.6317 - val_binary_accuracy: 0.6838 - 66ms/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "50/50 - 0s - loss: 0.6276 - binary_accuracy: 0.6659 - val_loss: 0.6279 - val_binary_accuracy: 0.6838 - 67ms/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "50/50 - 0s - loss: 0.6229 - binary_accuracy: 0.6659 - val_loss: 0.6345 - val_binary_accuracy: 0.6838 - 65ms/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "50/50 - 0s - loss: 0.6208 - binary_accuracy: 0.6659 - val_loss: 0.6271 - val_binary_accuracy: 0.6838 - 70ms/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "50/50 - 0s - loss: 0.6181 - binary_accuracy: 0.6666 - val_loss: 0.6310 - val_binary_accuracy: 0.6838 - 65ms/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "50/50 - 0s - loss: 0.6151 - binary_accuracy: 0.6662 - val_loss: 0.6266 - val_binary_accuracy: 0.6838 - 61ms/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "50/50 - 0s - loss: 0.6167 - binary_accuracy: 0.6650 - val_loss: 0.6272 - val_binary_accuracy: 0.6838 - 59ms/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "50/50 - 0s - loss: 0.6135 - binary_accuracy: 0.6659 - val_loss: 0.6261 - val_binary_accuracy: 0.6838 - 60ms/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "50/50 - 0s - loss: 0.6108 - binary_accuracy: 0.6659 - val_loss: 0.6251 - val_binary_accuracy: 0.6838 - 60ms/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "50/50 - 0s - loss: 0.6116 - binary_accuracy: 0.6653 - val_loss: 0.6250 - val_binary_accuracy: 0.6838 - 58ms/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "50/50 - 0s - loss: 0.6104 - binary_accuracy: 0.6656 - val_loss: 0.6276 - val_binary_accuracy: 0.6838 - 59ms/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "50/50 - 0s - loss: 0.6066 - binary_accuracy: 0.6653 - val_loss: 0.6238 - val_binary_accuracy: 0.6838 - 60ms/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "50/50 - 0s - loss: 0.6060 - binary_accuracy: 0.6628 - val_loss: 0.6283 - val_binary_accuracy: 0.6838 - 60ms/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "50/50 - 0s - loss: 0.6030 - binary_accuracy: 0.6666 - val_loss: 0.6221 - val_binary_accuracy: 0.6838 - 57ms/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "50/50 - 0s - loss: 0.6003 - binary_accuracy: 0.6634 - val_loss: 0.6246 - val_binary_accuracy: 0.6838 - 59ms/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "50/50 - 0s - loss: 0.6005 - binary_accuracy: 0.6653 - val_loss: 0.6274 - val_binary_accuracy: 0.6838 - 58ms/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "50/50 - 0s - loss: 0.6020 - binary_accuracy: 0.6637 - val_loss: 0.6177 - val_binary_accuracy: 0.6838 - 62ms/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "50/50 - 0s - loss: 0.5994 - binary_accuracy: 0.6722 - val_loss: 0.6271 - val_binary_accuracy: 0.6554 - 69ms/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "50/50 - 0s - loss: 0.6002 - binary_accuracy: 0.6672 - val_loss: 0.6265 - val_binary_accuracy: 0.6732 - 64ms/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "50/50 - 0s - loss: 0.5964 - binary_accuracy: 0.6716 - val_loss: 0.6272 - val_binary_accuracy: 0.6483 - 60ms/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "50/50 - 0s - loss: 0.5989 - binary_accuracy: 0.6722 - val_loss: 0.6339 - val_binary_accuracy: 0.6430 - 59ms/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "50/50 - 0s - loss: 0.5943 - binary_accuracy: 0.6716 - val_loss: 0.6292 - val_binary_accuracy: 0.6821 - 59ms/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "50/50 - 0s - loss: 0.5957 - binary_accuracy: 0.6747 - val_loss: 0.6327 - val_binary_accuracy: 0.6643 - 59ms/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "50/50 - 0s - loss: 0.5907 - binary_accuracy: 0.6785 - val_loss: 0.6462 - val_binary_accuracy: 0.6536 - 59ms/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "50/50 - 0s - loss: 0.5937 - binary_accuracy: 0.6650 - val_loss: 0.6326 - val_binary_accuracy: 0.6572 - 60ms/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "50/50 - 0s - loss: 0.5901 - binary_accuracy: 0.6810 - val_loss: 0.6315 - val_binary_accuracy: 0.6607 - 73ms/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "50/50 - 0s - loss: 0.5906 - binary_accuracy: 0.6760 - val_loss: 0.6380 - val_binary_accuracy: 0.6448 - 81ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "50/50 - 0s - loss: 0.5881 - binary_accuracy: 0.6813 - val_loss: 0.6364 - val_binary_accuracy: 0.6554 - 82ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "50/50 - 0s - loss: 0.5906 - binary_accuracy: 0.6763 - val_loss: 0.6454 - val_binary_accuracy: 0.6501 - 79ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "50/50 - 0s - loss: 0.5855 - binary_accuracy: 0.6841 - val_loss: 0.6317 - val_binary_accuracy: 0.6536 - 84ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "50/50 - 0s - loss: 0.5858 - binary_accuracy: 0.6807 - val_loss: 0.6371 - val_binary_accuracy: 0.6465 - 67ms/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "50/50 - 0s - loss: 0.5889 - binary_accuracy: 0.6794 - val_loss: 0.6362 - val_binary_accuracy: 0.6679 - 84ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "50/50 - 0s - loss: 0.5813 - binary_accuracy: 0.6891 - val_loss: 0.6402 - val_binary_accuracy: 0.6519 - 83ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "50/50 - 0s - loss: 0.5831 - binary_accuracy: 0.6835 - val_loss: 0.6448 - val_binary_accuracy: 0.6590 - 78ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "50/50 - 0s - loss: 0.5830 - binary_accuracy: 0.6857 - val_loss: 0.6404 - val_binary_accuracy: 0.6465 - 71ms/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "50/50 - 0s - loss: 0.5799 - binary_accuracy: 0.6898 - val_loss: 0.6381 - val_binary_accuracy: 0.6554 - 70ms/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "50/50 - 0s - loss: 0.5797 - binary_accuracy: 0.6910 - val_loss: 0.6463 - val_binary_accuracy: 0.6448 - 66ms/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "50/50 - 0s - loss: 0.5782 - binary_accuracy: 0.6948 - val_loss: 0.6474 - val_binary_accuracy: 0.6465 - 64ms/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "50/50 - 0s - loss: 0.5810 - binary_accuracy: 0.6891 - val_loss: 0.6461 - val_binary_accuracy: 0.6536 - 65ms/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "50/50 - 0s - loss: 0.5741 - binary_accuracy: 0.6986 - val_loss: 0.6465 - val_binary_accuracy: 0.6536 - 65ms/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "50/50 - 0s - loss: 0.5763 - binary_accuracy: 0.7008 - val_loss: 0.6541 - val_binary_accuracy: 0.6430 - 64ms/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "50/50 - 0s - loss: 0.5777 - binary_accuracy: 0.6954 - val_loss: 0.6532 - val_binary_accuracy: 0.6448 - 61ms/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "50/50 - 0s - loss: 0.5781 - binary_accuracy: 0.6923 - val_loss: 0.6480 - val_binary_accuracy: 0.6465 - 72ms/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "50/50 - 0s - loss: 0.5749 - binary_accuracy: 0.6960 - val_loss: 0.6504 - val_binary_accuracy: 0.6643 - 61ms/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "50/50 - 0s - loss: 0.5773 - binary_accuracy: 0.6957 - val_loss: 0.6536 - val_binary_accuracy: 0.6377 - 61ms/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "50/50 - 0s - loss: 0.5699 - binary_accuracy: 0.7004 - val_loss: 0.6568 - val_binary_accuracy: 0.6323 - 60ms/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "50/50 - 0s - loss: 0.5751 - binary_accuracy: 0.6920 - val_loss: 0.6612 - val_binary_accuracy: 0.6359 - 56ms/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "50/50 - 0s - loss: 0.5680 - binary_accuracy: 0.6979 - val_loss: 0.6591 - val_binary_accuracy: 0.6448 - 59ms/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "50/50 - 0s - loss: 0.5674 - binary_accuracy: 0.6982 - val_loss: 0.6635 - val_binary_accuracy: 0.6465 - 58ms/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "50/50 - 0s - loss: 0.5728 - binary_accuracy: 0.6973 - val_loss: 0.6665 - val_binary_accuracy: 0.6394 - 59ms/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "50/50 - 0s - loss: 0.5671 - binary_accuracy: 0.7039 - val_loss: 0.6641 - val_binary_accuracy: 0.6394 - 59ms/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "50/50 - 0s - loss: 0.5718 - binary_accuracy: 0.6992 - val_loss: 0.6627 - val_binary_accuracy: 0.6519 - 60ms/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "50/50 - 0s - loss: 0.5682 - binary_accuracy: 0.7039 - val_loss: 0.6657 - val_binary_accuracy: 0.6448 - 60ms/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "50/50 - 0s - loss: 0.5689 - binary_accuracy: 0.7026 - val_loss: 0.6764 - val_binary_accuracy: 0.6323 - 59ms/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "50/50 - 0s - loss: 0.5665 - binary_accuracy: 0.7042 - val_loss: 0.6581 - val_binary_accuracy: 0.6661 - 59ms/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "50/50 - 0s - loss: 0.5666 - binary_accuracy: 0.6973 - val_loss: 0.6712 - val_binary_accuracy: 0.6412 - 59ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "50/50 - 0s - loss: 0.5678 - binary_accuracy: 0.7029 - val_loss: 0.6723 - val_binary_accuracy: 0.6341 - 59ms/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "50/50 - 0s - loss: 0.5640 - binary_accuracy: 0.7011 - val_loss: 0.6769 - val_binary_accuracy: 0.6430 - 58ms/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "50/50 - 0s - loss: 0.5703 - binary_accuracy: 0.7023 - val_loss: 0.6652 - val_binary_accuracy: 0.6536 - 60ms/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "50/50 - 0s - loss: 0.5609 - binary_accuracy: 0.7042 - val_loss: 0.6706 - val_binary_accuracy: 0.6501 - 58ms/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "50/50 - 0s - loss: 0.5645 - binary_accuracy: 0.6960 - val_loss: 0.6851 - val_binary_accuracy: 0.6394 - 59ms/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "50/50 - 0s - loss: 0.5615 - binary_accuracy: 0.7042 - val_loss: 0.6807 - val_binary_accuracy: 0.6430 - 59ms/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "50/50 - 0s - loss: 0.5623 - binary_accuracy: 0.7061 - val_loss: 0.6954 - val_binary_accuracy: 0.6270 - 60ms/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "50/50 - 0s - loss: 0.5688 - binary_accuracy: 0.7004 - val_loss: 0.6809 - val_binary_accuracy: 0.6412 - 66ms/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "50/50 - 0s - loss: 0.5566 - binary_accuracy: 0.7102 - val_loss: 0.6979 - val_binary_accuracy: 0.6465 - 59ms/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "50/50 - 0s - loss: 0.5581 - binary_accuracy: 0.7102 - val_loss: 0.7064 - val_binary_accuracy: 0.6288 - 60ms/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "50/50 - 0s - loss: 0.5549 - binary_accuracy: 0.7077 - val_loss: 0.6940 - val_binary_accuracy: 0.6270 - 58ms/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "50/50 - 0s - loss: 0.5559 - binary_accuracy: 0.7077 - val_loss: 0.6912 - val_binary_accuracy: 0.6306 - 59ms/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "50/50 - 0s - loss: 0.5594 - binary_accuracy: 0.7152 - val_loss: 0.6852 - val_binary_accuracy: 0.6430 - 61ms/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "50/50 - 0s - loss: 0.5608 - binary_accuracy: 0.7064 - val_loss: 0.6988 - val_binary_accuracy: 0.6412 - 59ms/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "50/50 - 0s - loss: 0.5577 - binary_accuracy: 0.7089 - val_loss: 0.6963 - val_binary_accuracy: 0.6270 - 59ms/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "50/50 - 0s - loss: 0.5558 - binary_accuracy: 0.7045 - val_loss: 0.6993 - val_binary_accuracy: 0.6199 - 59ms/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "50/50 - 0s - loss: 0.5544 - binary_accuracy: 0.7077 - val_loss: 0.7008 - val_binary_accuracy: 0.6163 - 62ms/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "50/50 - 0s - loss: 0.5526 - binary_accuracy: 0.7136 - val_loss: 0.6910 - val_binary_accuracy: 0.6448 - 60ms/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "50/50 - 0s - loss: 0.5590 - binary_accuracy: 0.7055 - val_loss: 0.7027 - val_binary_accuracy: 0.6394 - 60ms/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "50/50 - 0s - loss: 0.5592 - binary_accuracy: 0.7039 - val_loss: 0.7123 - val_binary_accuracy: 0.6252 - 61ms/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "50/50 - 0s - loss: 0.5533 - binary_accuracy: 0.7098 - val_loss: 0.6996 - val_binary_accuracy: 0.6465 - 60ms/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "50/50 - 0s - loss: 0.5583 - binary_accuracy: 0.7105 - val_loss: 0.7063 - val_binary_accuracy: 0.6252 - 60ms/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "50/50 - 0s - loss: 0.5540 - binary_accuracy: 0.7086 - val_loss: 0.7119 - val_binary_accuracy: 0.6270 - 66ms/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "50/50 - 0s - loss: 0.5519 - binary_accuracy: 0.7142 - val_loss: 0.7075 - val_binary_accuracy: 0.6128 - 62ms/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "50/50 - 0s - loss: 0.5516 - binary_accuracy: 0.7149 - val_loss: 0.7225 - val_binary_accuracy: 0.6110 - 61ms/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "50/50 - 0s - loss: 0.5535 - binary_accuracy: 0.7083 - val_loss: 0.7023 - val_binary_accuracy: 0.6359 - 58ms/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "50/50 - 0s - loss: 0.5568 - binary_accuracy: 0.7061 - val_loss: 0.7186 - val_binary_accuracy: 0.6288 - 60ms/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "50/50 - 0s - loss: 0.5525 - binary_accuracy: 0.7111 - val_loss: 0.7303 - val_binary_accuracy: 0.6057 - 59ms/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "50/50 - 0s - loss: 0.5593 - binary_accuracy: 0.7130 - val_loss: 0.7258 - val_binary_accuracy: 0.6288 - 58ms/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "50/50 - 0s - loss: 0.5532 - binary_accuracy: 0.7086 - val_loss: 0.7258 - val_binary_accuracy: 0.6181 - 58ms/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "50/50 - 0s - loss: 0.5527 - binary_accuracy: 0.7083 - val_loss: 0.7188 - val_binary_accuracy: 0.6323 - 59ms/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "50/50 - 0s - loss: 0.5498 - binary_accuracy: 0.7095 - val_loss: 0.7425 - val_binary_accuracy: 0.6092 - 59ms/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "50/50 - 0s - loss: 0.5500 - binary_accuracy: 0.7029 - val_loss: 0.7264 - val_binary_accuracy: 0.6234 - 60ms/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "50/50 - 0s - loss: 0.5478 - binary_accuracy: 0.7133 - val_loss: 0.7189 - val_binary_accuracy: 0.6252 - 58ms/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "50/50 - 0s - loss: 0.5617 - binary_accuracy: 0.7039 - val_loss: 0.7185 - val_binary_accuracy: 0.6323 - 58ms/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "50/50 - 0s - loss: 0.5492 - binary_accuracy: 0.7124 - val_loss: 0.7268 - val_binary_accuracy: 0.6306 - 58ms/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "50/50 - 0s - loss: 0.5495 - binary_accuracy: 0.7155 - val_loss: 0.7152 - val_binary_accuracy: 0.6377 - 58ms/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "50/50 - 0s - loss: 0.5458 - binary_accuracy: 0.7158 - val_loss: 0.7250 - val_binary_accuracy: 0.6341 - 58ms/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "50/50 - 0s - loss: 0.5538 - binary_accuracy: 0.7033 - val_loss: 0.7295 - val_binary_accuracy: 0.6270 - 58ms/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "50/50 - 0s - loss: 0.5483 - binary_accuracy: 0.7155 - val_loss: 0.7156 - val_binary_accuracy: 0.6252 - 59ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "\n",
    "nn_model.compile(optimizer = 'adam',  \n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['binary_accuracy'] )\n",
    "history = nn_model.fit(train_x,train_y , epochs=100, validation_split=0.15, batch_size=64,verbose=2)\n",
    "d3 = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf4ac532",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential([\n",
    "                    Flatten(input_shape = (8, 15,3)),\n",
    "                    BatchNormalization(),\n",
    "                    Dense(2, activation = 'relu', input_shape = (360,)),\n",
    "                    BatchNormalization(),                    \n",
    "                Dense(4, activation = 'relu'),\n",
    "BatchNormalization(\n",
    "        momentum=0.75, \n",
    "        epsilon=0.0008,\n",
    "        beta_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05), \n",
    "        gamma_initializer=tf.keras.initializers.Constant(value=0.9)\n",
    "    ),                    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a7aa47d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 - 1s - loss: 0.7892 - binary_accuracy: 0.4853 - val_loss: 0.7999 - val_binary_accuracy: 0.4458 - 574ms/epoch - 11ms/step\n",
      "Epoch 2/100\n",
      "50/50 - 0s - loss: 0.6893 - binary_accuracy: 0.5518 - val_loss: 0.7076 - val_binary_accuracy: 0.3801 - 66ms/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "50/50 - 0s - loss: 0.6625 - binary_accuracy: 0.6286 - val_loss: 0.6594 - val_binary_accuracy: 0.6767 - 62ms/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "50/50 - 0s - loss: 0.6466 - binary_accuracy: 0.6468 - val_loss: 0.6469 - val_binary_accuracy: 0.6821 - 65ms/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "50/50 - 0s - loss: 0.6388 - binary_accuracy: 0.6584 - val_loss: 0.6441 - val_binary_accuracy: 0.6767 - 65ms/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "50/50 - 0s - loss: 0.6346 - binary_accuracy: 0.6644 - val_loss: 0.6400 - val_binary_accuracy: 0.6750 - 68ms/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "50/50 - 0s - loss: 0.6304 - binary_accuracy: 0.6653 - val_loss: 0.6376 - val_binary_accuracy: 0.6785 - 63ms/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "50/50 - 0s - loss: 0.6271 - binary_accuracy: 0.6650 - val_loss: 0.6382 - val_binary_accuracy: 0.6821 - 62ms/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "50/50 - 0s - loss: 0.6239 - binary_accuracy: 0.6647 - val_loss: 0.6344 - val_binary_accuracy: 0.6821 - 64ms/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "50/50 - 0s - loss: 0.6243 - binary_accuracy: 0.6662 - val_loss: 0.6307 - val_binary_accuracy: 0.6803 - 64ms/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "50/50 - 0s - loss: 0.6219 - binary_accuracy: 0.6656 - val_loss: 0.6363 - val_binary_accuracy: 0.6803 - 61ms/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "50/50 - 0s - loss: 0.6202 - binary_accuracy: 0.6659 - val_loss: 0.6322 - val_binary_accuracy: 0.6767 - 60ms/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "50/50 - 0s - loss: 0.6189 - binary_accuracy: 0.6644 - val_loss: 0.6308 - val_binary_accuracy: 0.6785 - 60ms/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "50/50 - 0s - loss: 0.6163 - binary_accuracy: 0.6662 - val_loss: 0.6351 - val_binary_accuracy: 0.6625 - 60ms/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "50/50 - 0s - loss: 0.6128 - binary_accuracy: 0.6675 - val_loss: 0.6498 - val_binary_accuracy: 0.6625 - 60ms/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "50/50 - 0s - loss: 0.6128 - binary_accuracy: 0.6678 - val_loss: 0.6380 - val_binary_accuracy: 0.6572 - 60ms/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "50/50 - 0s - loss: 0.6105 - binary_accuracy: 0.6753 - val_loss: 0.6339 - val_binary_accuracy: 0.6625 - 60ms/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "50/50 - 0s - loss: 0.6097 - binary_accuracy: 0.6706 - val_loss: 0.6432 - val_binary_accuracy: 0.6661 - 62ms/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "50/50 - 0s - loss: 0.6127 - binary_accuracy: 0.6678 - val_loss: 0.6399 - val_binary_accuracy: 0.6607 - 72ms/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "50/50 - 0s - loss: 0.6091 - binary_accuracy: 0.6694 - val_loss: 0.6355 - val_binary_accuracy: 0.6590 - 67ms/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "50/50 - 0s - loss: 0.6083 - binary_accuracy: 0.6728 - val_loss: 0.6378 - val_binary_accuracy: 0.6607 - 62ms/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "50/50 - 0s - loss: 0.6044 - binary_accuracy: 0.6757 - val_loss: 0.6449 - val_binary_accuracy: 0.6679 - 64ms/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "50/50 - 0s - loss: 0.6029 - binary_accuracy: 0.6747 - val_loss: 0.6423 - val_binary_accuracy: 0.6590 - 61ms/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "50/50 - 0s - loss: 0.6065 - binary_accuracy: 0.6757 - val_loss: 0.6522 - val_binary_accuracy: 0.6590 - 62ms/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "50/50 - 0s - loss: 0.6050 - binary_accuracy: 0.6801 - val_loss: 0.6538 - val_binary_accuracy: 0.6607 - 62ms/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "50/50 - 0s - loss: 0.6026 - binary_accuracy: 0.6731 - val_loss: 0.6568 - val_binary_accuracy: 0.6696 - 64ms/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "50/50 - 0s - loss: 0.6016 - binary_accuracy: 0.6826 - val_loss: 0.6432 - val_binary_accuracy: 0.6607 - 73ms/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "50/50 - 0s - loss: 0.6013 - binary_accuracy: 0.6822 - val_loss: 0.6418 - val_binary_accuracy: 0.6679 - 85ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "50/50 - 0s - loss: 0.5971 - binary_accuracy: 0.6882 - val_loss: 0.6505 - val_binary_accuracy: 0.6696 - 77ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "50/50 - 0s - loss: 0.5966 - binary_accuracy: 0.6785 - val_loss: 0.6510 - val_binary_accuracy: 0.6679 - 65ms/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "50/50 - 0s - loss: 0.5951 - binary_accuracy: 0.6797 - val_loss: 0.6510 - val_binary_accuracy: 0.6696 - 64ms/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "50/50 - 0s - loss: 0.5953 - binary_accuracy: 0.6807 - val_loss: 0.6548 - val_binary_accuracy: 0.6679 - 64ms/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "50/50 - 0s - loss: 0.5958 - binary_accuracy: 0.6882 - val_loss: 0.6688 - val_binary_accuracy: 0.6661 - 67ms/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "50/50 - 0s - loss: 0.5971 - binary_accuracy: 0.6879 - val_loss: 0.6637 - val_binary_accuracy: 0.6625 - 74ms/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "50/50 - 0s - loss: 0.5946 - binary_accuracy: 0.6854 - val_loss: 0.6646 - val_binary_accuracy: 0.6696 - 89ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "50/50 - 0s - loss: 0.5939 - binary_accuracy: 0.6857 - val_loss: 0.6578 - val_binary_accuracy: 0.6661 - 83ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "50/50 - 0s - loss: 0.5890 - binary_accuracy: 0.6907 - val_loss: 0.6622 - val_binary_accuracy: 0.6554 - 65ms/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "50/50 - 0s - loss: 0.5862 - binary_accuracy: 0.6904 - val_loss: 0.6654 - val_binary_accuracy: 0.6643 - 63ms/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "50/50 - 0s - loss: 0.5883 - binary_accuracy: 0.6907 - val_loss: 0.6580 - val_binary_accuracy: 0.6643 - 63ms/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "50/50 - 0s - loss: 0.5888 - binary_accuracy: 0.6923 - val_loss: 0.6650 - val_binary_accuracy: 0.6536 - 73ms/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "50/50 - 0s - loss: 0.5814 - binary_accuracy: 0.7008 - val_loss: 0.6693 - val_binary_accuracy: 0.6430 - 79ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "50/50 - 0s - loss: 0.5904 - binary_accuracy: 0.6838 - val_loss: 0.6694 - val_binary_accuracy: 0.6430 - 68ms/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "50/50 - 0s - loss: 0.5838 - binary_accuracy: 0.6929 - val_loss: 0.6628 - val_binary_accuracy: 0.6394 - 66ms/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "50/50 - 0s - loss: 0.5845 - binary_accuracy: 0.6876 - val_loss: 0.6900 - val_binary_accuracy: 0.6501 - 64ms/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "50/50 - 0s - loss: 0.5825 - binary_accuracy: 0.6879 - val_loss: 0.6798 - val_binary_accuracy: 0.6554 - 64ms/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "50/50 - 0s - loss: 0.5812 - binary_accuracy: 0.6973 - val_loss: 0.7016 - val_binary_accuracy: 0.6483 - 67ms/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "50/50 - 0s - loss: 0.5823 - binary_accuracy: 0.6923 - val_loss: 0.6830 - val_binary_accuracy: 0.6394 - 69ms/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "50/50 - 0s - loss: 0.5781 - binary_accuracy: 0.6992 - val_loss: 0.6821 - val_binary_accuracy: 0.6412 - 67ms/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "50/50 - 0s - loss: 0.5811 - binary_accuracy: 0.6926 - val_loss: 0.6787 - val_binary_accuracy: 0.6465 - 64ms/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "50/50 - 0s - loss: 0.5801 - binary_accuracy: 0.6986 - val_loss: 0.6777 - val_binary_accuracy: 0.6448 - 64ms/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "50/50 - 0s - loss: 0.5796 - binary_accuracy: 0.7011 - val_loss: 0.6973 - val_binary_accuracy: 0.6394 - 65ms/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "50/50 - 0s - loss: 0.5781 - binary_accuracy: 0.6998 - val_loss: 0.6745 - val_binary_accuracy: 0.6465 - 60ms/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "50/50 - 0s - loss: 0.5787 - binary_accuracy: 0.6979 - val_loss: 0.7113 - val_binary_accuracy: 0.6483 - 61ms/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "50/50 - 0s - loss: 0.5765 - binary_accuracy: 0.7008 - val_loss: 0.6854 - val_binary_accuracy: 0.6483 - 61ms/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "50/50 - 0s - loss: 0.5761 - binary_accuracy: 0.7045 - val_loss: 0.6799 - val_binary_accuracy: 0.6483 - 60ms/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "50/50 - 0s - loss: 0.5723 - binary_accuracy: 0.7023 - val_loss: 0.6906 - val_binary_accuracy: 0.6465 - 61ms/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "50/50 - 0s - loss: 0.5660 - binary_accuracy: 0.7089 - val_loss: 0.7007 - val_binary_accuracy: 0.6394 - 68ms/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "50/50 - 0s - loss: 0.5781 - binary_accuracy: 0.6967 - val_loss: 0.6946 - val_binary_accuracy: 0.6323 - 63ms/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "50/50 - 0s - loss: 0.5761 - binary_accuracy: 0.7048 - val_loss: 0.6831 - val_binary_accuracy: 0.6341 - 62ms/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "50/50 - 0s - loss: 0.5700 - binary_accuracy: 0.7020 - val_loss: 0.6880 - val_binary_accuracy: 0.6288 - 62ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "50/50 - 0s - loss: 0.5743 - binary_accuracy: 0.7023 - val_loss: 0.7089 - val_binary_accuracy: 0.6306 - 60ms/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "50/50 - 0s - loss: 0.5736 - binary_accuracy: 0.6973 - val_loss: 0.6910 - val_binary_accuracy: 0.6306 - 58ms/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "50/50 - 0s - loss: 0.5723 - binary_accuracy: 0.7048 - val_loss: 0.6934 - val_binary_accuracy: 0.6412 - 57ms/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "50/50 - 0s - loss: 0.5777 - binary_accuracy: 0.6954 - val_loss: 0.7038 - val_binary_accuracy: 0.6323 - 59ms/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "50/50 - 0s - loss: 0.5676 - binary_accuracy: 0.7017 - val_loss: 0.6899 - val_binary_accuracy: 0.6430 - 59ms/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "50/50 - 0s - loss: 0.5694 - binary_accuracy: 0.7039 - val_loss: 0.6796 - val_binary_accuracy: 0.6341 - 59ms/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "50/50 - 0s - loss: 0.5667 - binary_accuracy: 0.7105 - val_loss: 0.6873 - val_binary_accuracy: 0.6412 - 59ms/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "50/50 - 0s - loss: 0.5668 - binary_accuracy: 0.7045 - val_loss: 0.6972 - val_binary_accuracy: 0.6306 - 67ms/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "50/50 - 0s - loss: 0.5682 - binary_accuracy: 0.7055 - val_loss: 0.6960 - val_binary_accuracy: 0.6323 - 59ms/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "50/50 - 0s - loss: 0.5682 - binary_accuracy: 0.7014 - val_loss: 0.6927 - val_binary_accuracy: 0.6323 - 59ms/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "50/50 - 0s - loss: 0.5674 - binary_accuracy: 0.7048 - val_loss: 0.6935 - val_binary_accuracy: 0.6536 - 60ms/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "50/50 - 0s - loss: 0.5627 - binary_accuracy: 0.7073 - val_loss: 0.6949 - val_binary_accuracy: 0.6341 - 58ms/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "50/50 - 0s - loss: 0.5593 - binary_accuracy: 0.7077 - val_loss: 0.7035 - val_binary_accuracy: 0.6465 - 58ms/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "50/50 - 0s - loss: 0.5615 - binary_accuracy: 0.7124 - val_loss: 0.6946 - val_binary_accuracy: 0.6341 - 58ms/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "50/50 - 0s - loss: 0.5716 - binary_accuracy: 0.7061 - val_loss: 0.6938 - val_binary_accuracy: 0.6252 - 59ms/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "50/50 - 0s - loss: 0.5590 - binary_accuracy: 0.7117 - val_loss: 0.7003 - val_binary_accuracy: 0.6448 - 60ms/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "50/50 - 0s - loss: 0.5636 - binary_accuracy: 0.7086 - val_loss: 0.7104 - val_binary_accuracy: 0.6234 - 60ms/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "50/50 - 0s - loss: 0.5587 - binary_accuracy: 0.7133 - val_loss: 0.6927 - val_binary_accuracy: 0.6465 - 61ms/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "50/50 - 0s - loss: 0.5618 - binary_accuracy: 0.7111 - val_loss: 0.6959 - val_binary_accuracy: 0.6412 - 60ms/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "50/50 - 0s - loss: 0.5581 - binary_accuracy: 0.7089 - val_loss: 0.7047 - val_binary_accuracy: 0.6412 - 60ms/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "50/50 - 0s - loss: 0.5636 - binary_accuracy: 0.7077 - val_loss: 0.6901 - val_binary_accuracy: 0.6394 - 61ms/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "50/50 - 0s - loss: 0.5591 - binary_accuracy: 0.7036 - val_loss: 0.6993 - val_binary_accuracy: 0.6323 - 59ms/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "50/50 - 0s - loss: 0.5634 - binary_accuracy: 0.7055 - val_loss: 0.7002 - val_binary_accuracy: 0.6359 - 67ms/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "50/50 - 0s - loss: 0.5635 - binary_accuracy: 0.7039 - val_loss: 0.6876 - val_binary_accuracy: 0.6377 - 60ms/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "50/50 - 0s - loss: 0.5642 - binary_accuracy: 0.7077 - val_loss: 0.7111 - val_binary_accuracy: 0.6430 - 62ms/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "50/50 - 0s - loss: 0.5592 - binary_accuracy: 0.7089 - val_loss: 0.7007 - val_binary_accuracy: 0.6252 - 60ms/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "50/50 - 0s - loss: 0.5614 - binary_accuracy: 0.7092 - val_loss: 0.7333 - val_binary_accuracy: 0.6270 - 59ms/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "50/50 - 0s - loss: 0.5549 - binary_accuracy: 0.7092 - val_loss: 0.7451 - val_binary_accuracy: 0.6217 - 59ms/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "50/50 - 0s - loss: 0.5596 - binary_accuracy: 0.7048 - val_loss: 0.7092 - val_binary_accuracy: 0.6412 - 58ms/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "50/50 - 0s - loss: 0.5667 - binary_accuracy: 0.7102 - val_loss: 0.7262 - val_binary_accuracy: 0.6448 - 59ms/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "50/50 - 0s - loss: 0.5577 - binary_accuracy: 0.7073 - val_loss: 0.6887 - val_binary_accuracy: 0.6412 - 68ms/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "50/50 - 0s - loss: 0.5536 - binary_accuracy: 0.7158 - val_loss: 0.7119 - val_binary_accuracy: 0.6306 - 61ms/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "50/50 - 0s - loss: 0.5604 - binary_accuracy: 0.7042 - val_loss: 0.7033 - val_binary_accuracy: 0.6234 - 64ms/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "50/50 - 0s - loss: 0.5547 - binary_accuracy: 0.7168 - val_loss: 0.7119 - val_binary_accuracy: 0.6359 - 59ms/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "50/50 - 0s - loss: 0.5583 - binary_accuracy: 0.7120 - val_loss: 0.7280 - val_binary_accuracy: 0.6252 - 60ms/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "50/50 - 0s - loss: 0.5534 - binary_accuracy: 0.7136 - val_loss: 0.7269 - val_binary_accuracy: 0.6306 - 58ms/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "50/50 - 0s - loss: 0.5493 - binary_accuracy: 0.7174 - val_loss: 0.7319 - val_binary_accuracy: 0.6377 - 59ms/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "50/50 - 0s - loss: 0.5508 - binary_accuracy: 0.7168 - val_loss: 0.7275 - val_binary_accuracy: 0.6234 - 59ms/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "50/50 - 0s - loss: 0.5490 - binary_accuracy: 0.7114 - val_loss: 0.7306 - val_binary_accuracy: 0.6288 - 58ms/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "50/50 - 0s - loss: 0.5526 - binary_accuracy: 0.7127 - val_loss: 0.7328 - val_binary_accuracy: 0.6288 - 58ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "\n",
    "nn_model.compile(optimizer = 'adam',  \n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['binary_accuracy'] )\n",
    "history = nn_model.fit(train_x,train_y , epochs=100, validation_split=0.15, batch_size=64,verbose=2)\n",
    "d4 = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee9ef54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential([\n",
    "                    Flatten(input_shape = (8, 15,3)),\n",
    "                    BatchNormalization(),\n",
    "                    Dense(2, activation = 'relu', input_shape = (360,)),\n",
    "BatchNormalization(\n",
    "        momentum=0.75, \n",
    "        epsilon=0.0008,\n",
    "        beta_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05), \n",
    "        gamma_initializer=tf.keras.initializers.Constant(value=0.9)\n",
    "    ),                   Dense(4, activation = 'relu'),\n",
    "BatchNormalization(\n",
    "        momentum=0.75, \n",
    "        epsilon=0.0008,\n",
    "        beta_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05), \n",
    "        gamma_initializer=tf.keras.initializers.Constant(value=0.9)\n",
    "    ),                    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5831a87c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 - 1s - loss: 0.7431 - binary_accuracy: 0.5122 - val_loss: 0.7423 - val_binary_accuracy: 0.3694 - 578ms/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "50/50 - 0s - loss: 0.6715 - binary_accuracy: 0.5947 - val_loss: 0.6601 - val_binary_accuracy: 0.6785 - 65ms/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "50/50 - 0s - loss: 0.6512 - binary_accuracy: 0.6612 - val_loss: 0.6364 - val_binary_accuracy: 0.6838 - 64ms/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "50/50 - 0s - loss: 0.6403 - binary_accuracy: 0.6659 - val_loss: 0.6299 - val_binary_accuracy: 0.6838 - 66ms/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "50/50 - 0s - loss: 0.6332 - binary_accuracy: 0.6659 - val_loss: 0.6277 - val_binary_accuracy: 0.6838 - 63ms/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "50/50 - 0s - loss: 0.6291 - binary_accuracy: 0.6659 - val_loss: 0.6284 - val_binary_accuracy: 0.6838 - 62ms/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "50/50 - 0s - loss: 0.6256 - binary_accuracy: 0.6659 - val_loss: 0.6299 - val_binary_accuracy: 0.6838 - 66ms/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "50/50 - 0s - loss: 0.6212 - binary_accuracy: 0.6659 - val_loss: 0.6308 - val_binary_accuracy: 0.6838 - 75ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "50/50 - 0s - loss: 0.6215 - binary_accuracy: 0.6662 - val_loss: 0.6251 - val_binary_accuracy: 0.6838 - 60ms/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "50/50 - 0s - loss: 0.6184 - binary_accuracy: 0.6659 - val_loss: 0.6289 - val_binary_accuracy: 0.6838 - 61ms/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "50/50 - 0s - loss: 0.6142 - binary_accuracy: 0.6666 - val_loss: 0.6251 - val_binary_accuracy: 0.6838 - 60ms/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "50/50 - 0s - loss: 0.6154 - binary_accuracy: 0.6634 - val_loss: 0.6274 - val_binary_accuracy: 0.6838 - 60ms/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "50/50 - 0s - loss: 0.6108 - binary_accuracy: 0.6675 - val_loss: 0.6311 - val_binary_accuracy: 0.6696 - 60ms/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "50/50 - 0s - loss: 0.6082 - binary_accuracy: 0.6722 - val_loss: 0.6301 - val_binary_accuracy: 0.6767 - 59ms/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "50/50 - 0s - loss: 0.6065 - binary_accuracy: 0.6731 - val_loss: 0.6312 - val_binary_accuracy: 0.6679 - 62ms/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "50/50 - 0s - loss: 0.6068 - binary_accuracy: 0.6735 - val_loss: 0.6298 - val_binary_accuracy: 0.6554 - 67ms/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "50/50 - 0s - loss: 0.6001 - binary_accuracy: 0.6854 - val_loss: 0.6296 - val_binary_accuracy: 0.6483 - 64ms/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "50/50 - 0s - loss: 0.6040 - binary_accuracy: 0.6691 - val_loss: 0.6329 - val_binary_accuracy: 0.6590 - 63ms/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "50/50 - 0s - loss: 0.5994 - binary_accuracy: 0.6794 - val_loss: 0.6291 - val_binary_accuracy: 0.6625 - 66ms/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "50/50 - 0s - loss: 0.5999 - binary_accuracy: 0.6791 - val_loss: 0.6256 - val_binary_accuracy: 0.6643 - 69ms/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "50/50 - 0s - loss: 0.5981 - binary_accuracy: 0.6895 - val_loss: 0.6359 - val_binary_accuracy: 0.6554 - 67ms/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "50/50 - 0s - loss: 0.5988 - binary_accuracy: 0.6851 - val_loss: 0.6333 - val_binary_accuracy: 0.6501 - 64ms/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "50/50 - 0s - loss: 0.5989 - binary_accuracy: 0.6841 - val_loss: 0.6378 - val_binary_accuracy: 0.6501 - 63ms/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "50/50 - 0s - loss: 0.5942 - binary_accuracy: 0.6844 - val_loss: 0.6372 - val_binary_accuracy: 0.6465 - 63ms/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "50/50 - 0s - loss: 0.5928 - binary_accuracy: 0.6973 - val_loss: 0.6344 - val_binary_accuracy: 0.6519 - 64ms/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "50/50 - 0s - loss: 0.5926 - binary_accuracy: 0.6913 - val_loss: 0.6336 - val_binary_accuracy: 0.6590 - 63ms/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "50/50 - 0s - loss: 0.5944 - binary_accuracy: 0.6917 - val_loss: 0.6346 - val_binary_accuracy: 0.6430 - 64ms/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "50/50 - 0s - loss: 0.5881 - binary_accuracy: 0.6929 - val_loss: 0.6371 - val_binary_accuracy: 0.6536 - 66ms/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "50/50 - 0s - loss: 0.5921 - binary_accuracy: 0.6838 - val_loss: 0.6345 - val_binary_accuracy: 0.6501 - 66ms/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "50/50 - 0s - loss: 0.5879 - binary_accuracy: 0.6960 - val_loss: 0.6336 - val_binary_accuracy: 0.6625 - 61ms/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "50/50 - 0s - loss: 0.5954 - binary_accuracy: 0.6860 - val_loss: 0.6347 - val_binary_accuracy: 0.6625 - 61ms/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "50/50 - 0s - loss: 0.5911 - binary_accuracy: 0.6951 - val_loss: 0.6352 - val_binary_accuracy: 0.6377 - 61ms/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "50/50 - 0s - loss: 0.5890 - binary_accuracy: 0.6935 - val_loss: 0.6382 - val_binary_accuracy: 0.6572 - 60ms/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "50/50 - 0s - loss: 0.5857 - binary_accuracy: 0.6979 - val_loss: 0.6361 - val_binary_accuracy: 0.6519 - 61ms/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "50/50 - 0s - loss: 0.5823 - binary_accuracy: 0.7064 - val_loss: 0.6345 - val_binary_accuracy: 0.6625 - 61ms/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "50/50 - 0s - loss: 0.5855 - binary_accuracy: 0.7004 - val_loss: 0.6422 - val_binary_accuracy: 0.6501 - 63ms/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "50/50 - 0s - loss: 0.5857 - binary_accuracy: 0.7029 - val_loss: 0.6451 - val_binary_accuracy: 0.6501 - 62ms/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "50/50 - 0s - loss: 0.5807 - binary_accuracy: 0.7058 - val_loss: 0.6465 - val_binary_accuracy: 0.6465 - 59ms/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "50/50 - 0s - loss: 0.5825 - binary_accuracy: 0.7061 - val_loss: 0.6431 - val_binary_accuracy: 0.6590 - 59ms/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "50/50 - 0s - loss: 0.5831 - binary_accuracy: 0.6995 - val_loss: 0.6451 - val_binary_accuracy: 0.6501 - 59ms/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "50/50 - 0s - loss: 0.5828 - binary_accuracy: 0.7055 - val_loss: 0.6462 - val_binary_accuracy: 0.6519 - 60ms/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "50/50 - 0s - loss: 0.5816 - binary_accuracy: 0.7098 - val_loss: 0.6452 - val_binary_accuracy: 0.6377 - 59ms/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "50/50 - 0s - loss: 0.5798 - binary_accuracy: 0.7045 - val_loss: 0.6513 - val_binary_accuracy: 0.6501 - 60ms/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "50/50 - 0s - loss: 0.5804 - binary_accuracy: 0.7045 - val_loss: 0.6540 - val_binary_accuracy: 0.6394 - 59ms/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "50/50 - 0s - loss: 0.5782 - binary_accuracy: 0.7029 - val_loss: 0.6511 - val_binary_accuracy: 0.6501 - 59ms/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "50/50 - 0s - loss: 0.5782 - binary_accuracy: 0.7058 - val_loss: 0.6571 - val_binary_accuracy: 0.6412 - 60ms/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "50/50 - 0s - loss: 0.5822 - binary_accuracy: 0.7004 - val_loss: 0.6546 - val_binary_accuracy: 0.6377 - 60ms/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "50/50 - 0s - loss: 0.5755 - binary_accuracy: 0.7114 - val_loss: 0.6546 - val_binary_accuracy: 0.6394 - 61ms/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "50/50 - 0s - loss: 0.5753 - binary_accuracy: 0.7102 - val_loss: 0.6520 - val_binary_accuracy: 0.6341 - 67ms/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "50/50 - 0s - loss: 0.5767 - binary_accuracy: 0.7070 - val_loss: 0.6491 - val_binary_accuracy: 0.6465 - 63ms/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "50/50 - 0s - loss: 0.5747 - binary_accuracy: 0.7120 - val_loss: 0.6614 - val_binary_accuracy: 0.6217 - 62ms/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "50/50 - 0s - loss: 0.5784 - binary_accuracy: 0.7092 - val_loss: 0.6586 - val_binary_accuracy: 0.6306 - 69ms/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "50/50 - 0s - loss: 0.5744 - binary_accuracy: 0.7048 - val_loss: 0.6552 - val_binary_accuracy: 0.6377 - 64ms/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "50/50 - 0s - loss: 0.5729 - binary_accuracy: 0.7158 - val_loss: 0.6580 - val_binary_accuracy: 0.6306 - 62ms/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "50/50 - 0s - loss: 0.5762 - binary_accuracy: 0.7070 - val_loss: 0.6581 - val_binary_accuracy: 0.6394 - 61ms/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "50/50 - 0s - loss: 0.5724 - binary_accuracy: 0.7133 - val_loss: 0.6564 - val_binary_accuracy: 0.6394 - 65ms/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "50/50 - 0s - loss: 0.5727 - binary_accuracy: 0.7130 - val_loss: 0.6524 - val_binary_accuracy: 0.6359 - 65ms/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "50/50 - 0s - loss: 0.5721 - binary_accuracy: 0.7102 - val_loss: 0.6546 - val_binary_accuracy: 0.6359 - 62ms/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "50/50 - 0s - loss: 0.5718 - binary_accuracy: 0.7124 - val_loss: 0.6591 - val_binary_accuracy: 0.6448 - 62ms/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "50/50 - 0s - loss: 0.5661 - binary_accuracy: 0.7199 - val_loss: 0.6609 - val_binary_accuracy: 0.6394 - 63ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "50/50 - 0s - loss: 0.5751 - binary_accuracy: 0.7102 - val_loss: 0.6646 - val_binary_accuracy: 0.6448 - 63ms/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "50/50 - 0s - loss: 0.5668 - binary_accuracy: 0.7142 - val_loss: 0.6660 - val_binary_accuracy: 0.6412 - 63ms/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "50/50 - 0s - loss: 0.5706 - binary_accuracy: 0.7080 - val_loss: 0.6617 - val_binary_accuracy: 0.6394 - 60ms/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "50/50 - 0s - loss: 0.5716 - binary_accuracy: 0.7127 - val_loss: 0.6571 - val_binary_accuracy: 0.6536 - 63ms/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "50/50 - 0s - loss: 0.5697 - binary_accuracy: 0.7158 - val_loss: 0.6683 - val_binary_accuracy: 0.6323 - 60ms/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "50/50 - 0s - loss: 0.5676 - binary_accuracy: 0.7086 - val_loss: 0.6621 - val_binary_accuracy: 0.6412 - 61ms/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "50/50 - 0s - loss: 0.5680 - binary_accuracy: 0.7139 - val_loss: 0.6657 - val_binary_accuracy: 0.6412 - 57ms/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "50/50 - 0s - loss: 0.5710 - binary_accuracy: 0.7095 - val_loss: 0.6585 - val_binary_accuracy: 0.6377 - 58ms/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "50/50 - 0s - loss: 0.5623 - binary_accuracy: 0.7177 - val_loss: 0.6640 - val_binary_accuracy: 0.6465 - 58ms/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "50/50 - 0s - loss: 0.5686 - binary_accuracy: 0.7095 - val_loss: 0.6597 - val_binary_accuracy: 0.6394 - 61ms/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "50/50 - 0s - loss: 0.5663 - binary_accuracy: 0.7196 - val_loss: 0.6602 - val_binary_accuracy: 0.6448 - 64ms/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "50/50 - 0s - loss: 0.5616 - binary_accuracy: 0.7215 - val_loss: 0.6665 - val_binary_accuracy: 0.6359 - 62ms/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "50/50 - 0s - loss: 0.5655 - binary_accuracy: 0.7161 - val_loss: 0.6581 - val_binary_accuracy: 0.6323 - 60ms/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "50/50 - 0s - loss: 0.5640 - binary_accuracy: 0.7149 - val_loss: 0.6642 - val_binary_accuracy: 0.6394 - 61ms/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "50/50 - 0s - loss: 0.5666 - binary_accuracy: 0.7127 - val_loss: 0.6603 - val_binary_accuracy: 0.6412 - 60ms/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "50/50 - 0s - loss: 0.5667 - binary_accuracy: 0.7155 - val_loss: 0.6621 - val_binary_accuracy: 0.6377 - 66ms/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "50/50 - 0s - loss: 0.5626 - binary_accuracy: 0.7161 - val_loss: 0.6584 - val_binary_accuracy: 0.6359 - 62ms/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "50/50 - 0s - loss: 0.5625 - binary_accuracy: 0.7193 - val_loss: 0.6606 - val_binary_accuracy: 0.6234 - 66ms/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "50/50 - 0s - loss: 0.5598 - binary_accuracy: 0.7243 - val_loss: 0.6633 - val_binary_accuracy: 0.6430 - 69ms/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "50/50 - 0s - loss: 0.5626 - binary_accuracy: 0.7155 - val_loss: 0.6636 - val_binary_accuracy: 0.6341 - 61ms/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "50/50 - 0s - loss: 0.5634 - binary_accuracy: 0.7152 - val_loss: 0.6696 - val_binary_accuracy: 0.6252 - 60ms/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "50/50 - 0s - loss: 0.5584 - binary_accuracy: 0.7171 - val_loss: 0.6738 - val_binary_accuracy: 0.6306 - 62ms/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "50/50 - 0s - loss: 0.5641 - binary_accuracy: 0.7252 - val_loss: 0.6607 - val_binary_accuracy: 0.6288 - 63ms/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "50/50 - 0s - loss: 0.5582 - binary_accuracy: 0.7205 - val_loss: 0.6618 - val_binary_accuracy: 0.6465 - 62ms/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "50/50 - 0s - loss: 0.5627 - binary_accuracy: 0.7177 - val_loss: 0.6704 - val_binary_accuracy: 0.6341 - 60ms/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "50/50 - 0s - loss: 0.5616 - binary_accuracy: 0.7262 - val_loss: 0.6674 - val_binary_accuracy: 0.6288 - 60ms/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "50/50 - 0s - loss: 0.5552 - binary_accuracy: 0.7252 - val_loss: 0.6696 - val_binary_accuracy: 0.6341 - 61ms/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "50/50 - 0s - loss: 0.5601 - binary_accuracy: 0.7255 - val_loss: 0.6679 - val_binary_accuracy: 0.6359 - 61ms/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "50/50 - 0s - loss: 0.5553 - binary_accuracy: 0.7265 - val_loss: 0.6651 - val_binary_accuracy: 0.6323 - 61ms/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "50/50 - 0s - loss: 0.5595 - binary_accuracy: 0.7249 - val_loss: 0.6665 - val_binary_accuracy: 0.6323 - 62ms/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "50/50 - 0s - loss: 0.5557 - binary_accuracy: 0.7208 - val_loss: 0.6704 - val_binary_accuracy: 0.6270 - 63ms/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "50/50 - 0s - loss: 0.5579 - binary_accuracy: 0.7243 - val_loss: 0.6799 - val_binary_accuracy: 0.6234 - 63ms/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "50/50 - 0s - loss: 0.5565 - binary_accuracy: 0.7230 - val_loss: 0.6668 - val_binary_accuracy: 0.6323 - 60ms/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "50/50 - 0s - loss: 0.5514 - binary_accuracy: 0.7265 - val_loss: 0.6708 - val_binary_accuracy: 0.6306 - 59ms/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "50/50 - 0s - loss: 0.5593 - binary_accuracy: 0.7174 - val_loss: 0.6724 - val_binary_accuracy: 0.6394 - 59ms/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "50/50 - 0s - loss: 0.5549 - binary_accuracy: 0.7280 - val_loss: 0.6765 - val_binary_accuracy: 0.6270 - 59ms/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "50/50 - 0s - loss: 0.5578 - binary_accuracy: 0.7215 - val_loss: 0.6688 - val_binary_accuracy: 0.6412 - 58ms/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "50/50 - 0s - loss: 0.5551 - binary_accuracy: 0.7287 - val_loss: 0.6752 - val_binary_accuracy: 0.6394 - 59ms/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "50/50 - 0s - loss: 0.5589 - binary_accuracy: 0.7221 - val_loss: 0.6703 - val_binary_accuracy: 0.6377 - 58ms/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "50/50 - 0s - loss: 0.5560 - binary_accuracy: 0.7252 - val_loss: 0.6773 - val_binary_accuracy: 0.6288 - 59ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "\n",
    "nn_model.compile(optimizer = 'adam',  \n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['binary_accuracy'] )\n",
    "history = nn_model.fit(train_x,train_y , epochs=100, validation_split=0.15, batch_size=64,verbose=2)\n",
    "d5 = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d890a2f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.555067</td>\n",
       "      <td>0.728670</td>\n",
       "      <td>0.675248</td>\n",
       "      <td>0.639432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.554863</td>\n",
       "      <td>0.728043</td>\n",
       "      <td>0.676504</td>\n",
       "      <td>0.626998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.555327</td>\n",
       "      <td>0.726474</td>\n",
       "      <td>0.665092</td>\n",
       "      <td>0.632327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.551363</td>\n",
       "      <td>0.726474</td>\n",
       "      <td>0.670838</td>\n",
       "      <td>0.630551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.561571</td>\n",
       "      <td>0.726161</td>\n",
       "      <td>0.667391</td>\n",
       "      <td>0.628774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.618378</td>\n",
       "      <td>0.665935</td>\n",
       "      <td>0.628947</td>\n",
       "      <td>0.683837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.615378</td>\n",
       "      <td>0.663425</td>\n",
       "      <td>0.627443</td>\n",
       "      <td>0.683837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.651184</td>\n",
       "      <td>0.661230</td>\n",
       "      <td>0.636418</td>\n",
       "      <td>0.683837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.671508</td>\n",
       "      <td>0.594730</td>\n",
       "      <td>0.660143</td>\n",
       "      <td>0.678508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743093</td>\n",
       "      <td>0.512233</td>\n",
       "      <td>0.742331</td>\n",
       "      <td>0.369449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  binary_accuracy  val_loss  val_binary_accuracy\n",
       "97  0.555067         0.728670  0.675248             0.639432\n",
       "95  0.554863         0.728043  0.676504             0.626998\n",
       "88  0.555327         0.726474  0.665092             0.632327\n",
       "93  0.551363         0.726474  0.670838             0.630551\n",
       "85  0.561571         0.726161  0.667391             0.628774\n",
       "..       ...              ...       ...                  ...\n",
       "9   0.618378         0.665935  0.628947             0.683837\n",
       "11  0.615378         0.663425  0.627443             0.683837\n",
       "2   0.651184         0.661230  0.636418             0.683837\n",
       "1   0.671508         0.594730  0.660143             0.678508\n",
       "0   0.743093         0.512233  0.742331             0.369449\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5.sort_values(by=['binary_accuracy','val_binary_accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e731d8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>model5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>validation accuracy</th>\n",
       "      <td>64.4%</td>\n",
       "      <td>65.36%</td>\n",
       "      <td>63.41%</td>\n",
       "      <td>63.76%</td>\n",
       "      <td>63.94%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model1  model2  model3  model4  model5\n",
       "validation accuracy  64.4%  65.36%  63.41%  63.76%  63.94%"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array([['64.4%', '65.36%', '63.41%','63.76%','63.94%']]),\n",
    "                   columns=['model1', 'model2','model3','model4','model5'],index=['validation accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
